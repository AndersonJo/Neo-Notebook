{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%pylab inline\n",
    "import tensorflow as tf\n",
    "import struct, gzip\n",
    "import Image\n",
    "from tensorflow.examples.tutorials.mnist import input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = genfromtxt('../data/exem/machine-error01.csv', skip_header=True, delimiter=',')\n",
    "errors = data[:, 0]\n",
    "data = data[:,2:]\n",
    "\n",
    "train_errors = errors[:11000]\n",
    "train_data = data[:11000, :]\n",
    "\n",
    "test_errors = errors[11000:]\n",
    "test_data = data[11000:, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Parameters\n",
    "learning_rate = 0.001\n",
    "training_epochs = 20\n",
    "batch_size = 100\n",
    "display_step = 1\n",
    "n_steps = 6 * 60\n",
    "\n",
    "# Network Parameters\n",
    "n_hidden_1 = 256 # 1st layer number of features\n",
    "n_hidden_2 = 256 # 2nd layer number of features\n",
    "n_input = 30 # MNIST data input (img shape: 28*28)\n",
    "n_classes = 10 # MNIST total classes (0-9 digits)\n",
    "\n",
    "# tf Graph input\n",
    "x = tf.placeholder(\"float\", [None, n_input], name='x')\n",
    "y = tf.placeholder(\"float\", [None, 1], name='y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  47.    0.    0. ...,   48.  461.   78.]\n",
      " [  47.    0.    0. ...,   48.  461.   78.]\n",
      " [  47.    0.    0. ...,   48.  461.   78.]\n",
      " ..., \n",
      " [  44.   33.   23. ...,   48.  461.   78.]\n",
      " [  44.   33.   22. ...,   48.  461.   78.]\n",
      " [  44.   33.   22. ...,   48.  461.   78.]] [ 1.]\n"
     ]
    }
   ],
   "source": [
    "def next_batch(data, valid_data, n_sample=360, n_steps=n_steps):\n",
    "    nrow, ncol = data.shape\n",
    "    maximum = nrow - n_sample - n_steps\n",
    "    idx = randint(0, maximum)\n",
    "    batch_xs = data[idx:idx+n_sample,:]\n",
    "    batch_y = valid_data[idx + n_sample + n_steps:idx + n_sample + n_steps + 1]\n",
    "    return batch_xs, batch_y\n",
    "\n",
    "while True:\n",
    "    batch_xs, batch_y = next_batch(train_data, train_errors)\n",
    "    print batch_xs, batch_y\n",
    "    if batch_y == 1.:\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(?, 30)\n",
      "(30, 256)\n",
      "(?, 256)\n",
      "(?, 1)\n",
      "(?, 1)\n"
     ]
    }
   ],
   "source": [
    "weight_1 = tf.Variable(tf.random_normal([n_input, n_hidden_1]), name='weight1')\n",
    "bias_1 = tf.Variable(tf.random_normal([n_hidden_1]), name='bias1')\n",
    "layer_1 = tf.add(tf.matmul(x, weight_1), bias_1, name='layer1')\n",
    "layer_1 = tf.nn.relu(layer_1)\n",
    "\n",
    "weight_2 = tf.Variable(tf.random_normal([n_hidden_1, n_hidden_2]), name='weight2')\n",
    "bias_2 = tf.Variable(tf.random_normal([n_hidden_2]), name='bias2')\n",
    "layer_2 = tf.add(tf.matmul(layer_1, weight_2), bias_2, name='layer2')\n",
    "layer_2 = tf.nn.relu(layer_2)\n",
    "\n",
    "weight_3 = tf.Variable(tf.random_normal([n_hidden_2, 1]))\n",
    "bias_3 = tf.Variable(tf.random_normal([1]))\n",
    "layer_3 = tf.add(tf.matmul(layer_2, weight_3), bias_3)\n",
    "layer_3 = tf.nn.relu(layer_3)\n",
    "\n",
    "weight_4 = tf.Variable(tf.random_normal([1, 1]))\n",
    "layer_4 = tf.matmul(layer_3, weight_4)\n",
    "layer_4 = tf.nn.relu(layer_4)\n",
    "\n",
    "# y_ = tf.placeholder(tf.float32, [None, 2])\n",
    "# cross_entropy = tf.reduce_mean(-tf.reduce_sum(y_ * tf.log(y), reduction_indices=[1]))\n",
    "# train_step = tf.train.GradientDescentOptimizer(0.5).minimize(cross_entropy)\n",
    "\n",
    "\n",
    "print x.get_shape()\n",
    "print weight_1.get_shape()\n",
    "print layer_1.get_shape()\n",
    "print layer_3.get_shape()\n",
    "print layer_4.get_shape()\n",
    "# print cross_entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  41.   33.   22. ...,   48.  461.   78.]\n",
      " [  41.   33.   23. ...,   48.  461.   78.]\n",
      " [  41.   33.    0. ...,   48.  461.   78.]\n",
      " ..., \n",
      " [  38.  340.   33. ...,   48.  461.   78.]\n",
      " [  38.  341.   32. ...,   48.  461.   78.]\n",
      " [  38.  340.   33. ...,   48.  461.   78.]] [ 1.]\n",
      "[array([[ 4439651.5    ],\n",
      "       [ 4436883.     ],\n",
      "       [  253481.125  ],\n",
      "       [ 4436143.     ],\n",
      "       [ 4435364.5    ],\n",
      "       [ 5507674.5    ],\n",
      "       [ 4437723.5    ],\n",
      "       [ 4437858.5    ],\n",
      "       [ 4433996.     ],\n",
      "       [ 4437374.5    ],\n",
      "       [  253684.90625],\n",
      "       [ 4433779.5    ],\n",
      "       [ 5483043.     ],\n",
      "       [ 5482218.     ],\n",
      "       [ 4438618.     ],\n",
      "       [ 4438225.5    ],\n",
      "       [ 4463108.5    ],\n",
      "       [ 4440846.     ],\n",
      "       [ 4438281.5    ],\n",
      "       [ 4442113.     ],\n",
      "       [ 5482361.5    ],\n",
      "       [ 5485146.     ],\n",
      "       [ 4441059.5    ],\n",
      "       [ 4441298.     ],\n",
      "       [ 4440623.     ],\n",
      "       [ 4444593.5    ],\n",
      "       [ 4451723.5    ],\n",
      "       [ 5489477.5    ],\n",
      "       [ 5489907.     ],\n",
      "       [  263936.90625],\n",
      "       [ 4443523.5    ],\n",
      "       [ 4447359.     ],\n",
      "       [ 4445911.     ],\n",
      "       [ 4442521.5    ],\n",
      "       [ 4443072.5    ],\n",
      "       [ 5473554.5    ],\n",
      "       [ 5484783.5    ],\n",
      "       [ 4441778.     ],\n",
      "       [ 4442520.5    ],\n",
      "       [ 4442128.     ],\n",
      "       [ 4443910.5    ],\n",
      "       [ 4452828.5    ],\n",
      "       [ 4447533.5    ],\n",
      "       [ 5500170.5    ],\n",
      "       [ 4444920.5    ],\n",
      "       [ 4448114.     ],\n",
      "       [ 4445470.5    ],\n",
      "       [ 4445905.     ],\n",
      "       [ 4449637.     ],\n",
      "       [ 4450664.5    ],\n",
      "       [ 5488708.5    ],\n",
      "       [ 5492307.     ],\n",
      "       [ 4451704.5    ],\n",
      "       [ 4453247.5    ],\n",
      "       [ 4453730.5    ],\n",
      "       [ 4448554.     ],\n",
      "       [ 4474403.5    ],\n",
      "       [ 4448311.5    ],\n",
      "       [ 5514874.5    ],\n",
      "       [ 5489073.     ],\n",
      "       [ 4447002.     ],\n",
      "       [ 4447631.     ],\n",
      "       [ 4451218.5    ],\n",
      "       [ 4448532.5    ],\n",
      "       [ 5490445.5    ],\n",
      "       [ 5490569.     ],\n",
      "       [ 4452487.     ],\n",
      "       [ 4449839.     ],\n",
      "       [ 4475579.     ],\n",
      "       [ 4450349.5    ],\n",
      "       [ 4450494.5    ],\n",
      "       [ 4451111.5    ],\n",
      "       [ 5495298.     ],\n",
      "       [ 5500485.     ],\n",
      "       [ 4454430.     ],\n",
      "       [ 4451083.5    ],\n",
      "       [ 4451098.5    ],\n",
      "       [ 4451375.     ],\n",
      "       [ 4450980.5    ],\n",
      "       [ 4451223.     ],\n",
      "       [ 4477253.     ],\n",
      "       [ 4453656.5    ],\n",
      "       [ 4453488.     ],\n",
      "       [ 4453757.5    ],\n",
      "       [ 4477209.5    ],\n",
      "       [       0.     ],\n",
      "       [       0.     ],\n",
      "       [       0.     ],\n",
      "       [ 5492117.     ],\n",
      "       [ 5517556.5    ],\n",
      "       [       0.     ],\n",
      "       [ 4452827.5    ],\n",
      "       [ 4449787.5    ],\n",
      "       [ 4452438.     ],\n",
      "       [ 5488453.     ],\n",
      "       [ 5488847.     ],\n",
      "       [ 4447846.5    ],\n",
      "       [ 5488541.5    ],\n",
      "       [ 4441107.     ],\n",
      "       [ 4446731.     ],\n",
      "       [ 4447480.5    ],\n",
      "       [ 4449569.5    ],\n",
      "       [ 4449167.5    ],\n",
      "       [       0.     ],\n",
      "       [ 4447552.5    ],\n",
      "       [ 4469496.5    ],\n",
      "       [       0.     ],\n",
      "       [ 4440612.     ],\n",
      "       [ 4469502.     ],\n",
      "       [       0.     ],\n",
      "       [       0.     ],\n",
      "       [       0.     ],\n",
      "       [ 5485231.5    ],\n",
      "       [       0.     ],\n",
      "       [       0.     ],\n",
      "       [       0.     ],\n",
      "       [       0.     ],\n",
      "       [ 4443064.     ],\n",
      "       [       0.     ],\n",
      "       [       0.     ],\n",
      "       [       0.     ],\n",
      "       [       0.     ],\n",
      "       [ 4441503.     ],\n",
      "       [ 4442224.     ],\n",
      "       [       0.     ],\n",
      "       [  250673.90625],\n",
      "       [ 4443048.5    ],\n",
      "       [ 4441537.     ],\n",
      "       [ 4440691.5    ],\n",
      "       [ 4441788.     ],\n",
      "       [ 4442705.     ],\n",
      "       [       0.     ],\n",
      "       [ 4447099.     ],\n",
      "       [ 5483488.5    ],\n",
      "       [ 5483299.     ],\n",
      "       [ 5484418.5    ],\n",
      "       [       0.     ],\n",
      "       [       0.     ],\n",
      "       [ 4450385.     ],\n",
      "       [       0.     ],\n",
      "       [       0.     ],\n",
      "       [       0.     ],\n",
      "       [ 5487016.     ],\n",
      "       [ 5489195.5    ],\n",
      "       [ 4447304.5    ],\n",
      "       [ 4470604.5    ],\n",
      "       [ 4472205.     ],\n",
      "       [ 4448318.     ],\n",
      "       [       0.     ],\n",
      "       [       0.     ],\n",
      "       [ 4454708.     ],\n",
      "       [ 4448281.     ],\n",
      "       [ 4452791.     ],\n",
      "       [ 4448971.5    ],\n",
      "       [ 4445464.5    ],\n",
      "       [ 4453840.5    ],\n",
      "       [       0.     ],\n",
      "       [ 5491768.5    ],\n",
      "       [       0.     ],\n",
      "       [ 4453324.5    ],\n",
      "       [       0.     ],\n",
      "       [ 4455907.     ],\n",
      "       [ 4455254.5    ],\n",
      "       [ 4451191.5    ],\n",
      "       [       0.     ],\n",
      "       [       0.     ],\n",
      "       [       0.     ],\n",
      "       [       0.     ],\n",
      "       [       0.     ],\n",
      "       [       0.     ],\n",
      "       [ 4457212.5    ],\n",
      "       [       0.     ],\n",
      "       [       0.     ],\n",
      "       [       0.     ],\n",
      "       [ 4452126.5    ],\n",
      "       [ 4452129.5    ],\n",
      "       [ 4457202.5    ],\n",
      "       [ 4454319.5    ],\n",
      "       [ 5500228.5    ],\n",
      "       [ 4459505.5    ],\n",
      "       [ 4458225.5    ],\n",
      "       [ 4459656.     ],\n",
      "       [ 4460053.5    ],\n",
      "       [ 4461594.     ],\n",
      "       [ 5502816.5    ],\n",
      "       [ 5506585.     ],\n",
      "       [ 5506943.5    ],\n",
      "       [ 4466638.5    ],\n",
      "       [ 4466508.5    ],\n",
      "       [ 4463172.     ],\n",
      "       [ 5508259.5    ],\n",
      "       [ 5505605.     ],\n",
      "       [ 4461550.5    ],\n",
      "       [ 4462385.5    ],\n",
      "       [ 4461236.     ],\n",
      "       [ 4461551.     ],\n",
      "       [ 5502916.5    ],\n",
      "       [ 5527523.     ],\n",
      "       [ 4463137.     ],\n",
      "       [ 4463102.5    ],\n",
      "       [ 4464085.     ],\n",
      "       [ 4467457.5    ],\n",
      "       [ 4467890.5    ],\n",
      "       [ 5521038.     ],\n",
      "       [ 5512029.5    ],\n",
      "       [ 4468410.5    ],\n",
      "       [ 4469208.     ],\n",
      "       [ 4469910.     ],\n",
      "       [ 5540290.     ],\n",
      "       [ 4498786.     ],\n",
      "       [ 4474924.5    ],\n",
      "       [ 4474759.     ],\n",
      "       [ 4477170.5    ],\n",
      "       [ 5517051.5    ],\n",
      "       [ 5517512.     ],\n",
      "       [ 4472505.5    ],\n",
      "       [ 4499131.5    ],\n",
      "       [       0.     ],\n",
      "       [ 5512805.5    ],\n",
      "       [ 4492849.5    ],\n",
      "       [ 4471924.     ],\n",
      "       [ 4463680.5    ],\n",
      "       [ 4488427.5    ],\n",
      "       [       0.     ],\n",
      "       [ 4461509.5    ],\n",
      "       [       0.     ],\n",
      "       [       0.     ],\n",
      "       [ 4460635.     ],\n",
      "       [ 4459824.5    ],\n",
      "       [ 4458559.5    ],\n",
      "       [ 4458559.5    ],\n",
      "       [ 5500636.     ],\n",
      "       [ 4460892.5    ],\n",
      "       [ 4456712.5    ],\n",
      "       [ 4459685.5    ],\n",
      "       [ 5496521.5    ],\n",
      "       [ 5495778.     ],\n",
      "       [ 4454936.5    ],\n",
      "       [ 4455126.5    ],\n",
      "       [ 4453660.     ],\n",
      "       [ 4461423.     ],\n",
      "       [ 5494264.5    ],\n",
      "       [ 4450976.5    ],\n",
      "       [ 4451471.5    ],\n",
      "       [ 4472106.5    ],\n",
      "       [ 5488364.5    ],\n",
      "       [ 5488983.5    ],\n",
      "       [ 4445153.     ],\n",
      "       [ 4445153.5    ],\n",
      "       [ 4445199.5    ],\n",
      "       [ 4447196.5    ],\n",
      "       [ 4447595.     ],\n",
      "       [ 5483545.5    ],\n",
      "       [ 4443363.     ],\n",
      "       [ 4446647.5    ],\n",
      "       [ 4467989.5    ],\n",
      "       [ 4442825.     ],\n",
      "       [ 4441795.5    ],\n",
      "       [ 5487583.5    ],\n",
      "       [ 4441863.     ],\n",
      "       [ 4440791.5    ],\n",
      "       [       0.     ],\n",
      "       [       0.     ],\n",
      "       [       0.     ],\n",
      "       [ 4440258.     ],\n",
      "       [ 4441141.5    ],\n",
      "       [ 4439978.5    ],\n",
      "       [ 4439778.     ],\n",
      "       [ 4439176.     ],\n",
      "       [ 5483439.     ],\n",
      "       [       0.     ],\n",
      "       [       0.     ],\n",
      "       [       0.     ],\n",
      "       [ 4441405.     ],\n",
      "       [ 4462657.5    ],\n",
      "       [ 5482016.5    ],\n",
      "       [ 5484602.5    ],\n",
      "       [ 4432922.5    ],\n",
      "       [ 4441459.     ],\n",
      "       [ 4437845.     ],\n",
      "       [ 4438502.     ],\n",
      "       [ 4441828.     ],\n",
      "       [ 4439022.5    ],\n",
      "       [       0.     ],\n",
      "       [       0.     ],\n",
      "       [       0.     ],\n",
      "       [ 4429920.5    ],\n",
      "       [  160303.6875 ],\n",
      "       [ 4429521.5    ],\n",
      "       [ 4430623.     ],\n",
      "       [ 4430770.     ],\n",
      "       [ 4430409.5    ],\n",
      "       [       0.     ],\n",
      "       [       0.     ],\n",
      "       [ 4430555.     ],\n",
      "       [ 4431622.     ],\n",
      "       [ 5481022.5    ],\n",
      "       [ 4432912.5    ],\n",
      "       [ 4432791.5    ],\n",
      "       [ 4431326.5    ],\n",
      "       [ 5478984.5    ],\n",
      "       [ 4432693.5    ],\n",
      "       [       0.     ],\n",
      "       [       0.     ],\n",
      "       [       0.     ],\n",
      "       [ 4430734.     ],\n",
      "       [ 4430787.5    ],\n",
      "       [ 4430558.5    ],\n",
      "       [ 5478988.     ],\n",
      "       [ 5478805.5    ],\n",
      "       [ 4430979.5    ],\n",
      "       [ 5470418.5    ],\n",
      "       [       0.     ],\n",
      "       [       0.     ],\n",
      "       [       0.     ],\n",
      "       [ 4421626.5    ],\n",
      "       [ 4421522.5    ],\n",
      "       [ 4422236.     ],\n",
      "       [ 4421902.     ],\n",
      "       [ 4421858.     ],\n",
      "       [ 4449170.     ],\n",
      "       [ 4422088.5    ],\n",
      "       [ 4423868.     ],\n",
      "       [       0.     ],\n",
      "       [       0.     ],\n",
      "       [       0.     ],\n",
      "       [       0.     ],\n",
      "       [ 4423543.5    ],\n",
      "       [ 4423449.5    ],\n",
      "       [ 4420755.5    ],\n",
      "       [       0.     ],\n",
      "       [ 4424746.5    ],\n",
      "       [       0.     ],\n",
      "       [       0.     ],\n",
      "       [       0.     ],\n",
      "       [       0.     ],\n",
      "       [       0.     ],\n",
      "       [       0.     ],\n",
      "       [       0.     ],\n",
      "       [ 4424989.5    ],\n",
      "       [       0.     ],\n",
      "       [       0.     ],\n",
      "       [       0.     ],\n",
      "       [ 4423511.5    ],\n",
      "       [ 4422109.5    ],\n",
      "       [ 4423975.5    ],\n",
      "       [ 4425296.     ],\n",
      "       [       0.     ],\n",
      "       [       0.     ],\n",
      "       [ 4425396.     ],\n",
      "       [ 4422136.     ],\n",
      "       [ 4421132.5    ],\n",
      "       [ 4447172.     ],\n",
      "       [ 4421063.5    ],\n",
      "       [       0.     ],\n",
      "       [       0.     ],\n",
      "       [ 4422610.     ],\n",
      "       [       0.     ],\n",
      "       [       0.     ],\n",
      "       [       0.     ]], dtype=float32)]\n"
     ]
    }
   ],
   "source": [
    "# Initializing the variables\n",
    "init = tf.initialize_all_variables()\n",
    "\n",
    "# Launch the graph\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    batch_x, batch_y = next_batch(train_data, train_errors)\n",
    "    print batch_x, batch_y\n",
    "    result = sess.run([layer_4], feed_dict={x: batch_x, y: [batch_y]})\n",
    "    print result\n",
    "#     print sess.run([cross_entropy], feed_dict={y_:batch_y})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
