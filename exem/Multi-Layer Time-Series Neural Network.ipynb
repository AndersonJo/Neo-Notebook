{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%pylab inline\n",
    "import tensorflow as tf\n",
    "import struct, gzip\n",
    "import Image\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = genfromtxt('../data/exem/machine-error01.csv', skip_header=True, delimiter=',')\n",
    "errors = data[:, 0]\n",
    "data = data[:,2:]\n",
    "\n",
    "train_errors = errors[:11000]\n",
    "train_data = data[:11000, :]\n",
    "\n",
    "test_errors = errors[11000:]\n",
    "test_data = data[11000:, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2,)\n"
     ]
    }
   ],
   "source": [
    "# Parameters\n",
    "learning_rate = 0.001\n",
    "training_epochs = 20\n",
    "batch_size = 100\n",
    "display_step = 1\n",
    "n_steps = 6\n",
    "\n",
    "# Network Parameters\n",
    "n_hidden_1 = 1024 # 1st layer number of features\n",
    "n_hidden_2 = 512 # 2nd layer number of features\n",
    "n_input = 30 # MNIST data input (img shape: 28*28)\n",
    "n_classes = 10 # MNIST total classes (0-9 digits)\n",
    "\n",
    "# tf Graph input\n",
    "x = tf.placeholder(\"float\", [None, n_input], name='x')\n",
    "y = tf.placeholder(\"float\", [2], name='y')\n",
    "print y.get_shape()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1] (1,) (2,)\n"
     ]
    }
   ],
   "source": [
    "def next_batch(data, valid_data, n_sample=360, n_steps=n_steps):\n",
    "    nrow, ncol = data.shape\n",
    "    maximum = nrow - n_sample - n_steps\n",
    "    idx = randint(0, maximum)\n",
    "    batch_xs = data[idx:idx+n_sample,:]\n",
    "    batch_y = valid_data[idx + n_sample + n_steps:idx + n_sample + n_steps + 1][0]\n",
    "    batch_y = [0, 1] if batch_y == 1 else [1, 0]\n",
    "    return batch_xs, batch_y\n",
    "\n",
    "\n",
    "batch_xs, batch_y = next_batch(train_data, train_errors)\n",
    "print batch_y, tf.shape(batch_y).get_shape(), y.get_shape()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "weight_1 = tf.Variable(tf.random_normal([n_input, n_hidden_1]), name='weight1')\n",
    "bias_1 = tf.Variable(tf.random_normal([n_hidden_1]), name='bias1')\n",
    "layer_1 = tf.add(tf.matmul(x, weight_1), bias_1, name='layer1')\n",
    "layer_1 = tf.nn.sigmoid(layer_1)\n",
    "\n",
    "weight_2 = tf.Variable(tf.random_normal([n_hidden_1, n_hidden_2]), name='weight2')\n",
    "bias_2 = tf.Variable(tf.random_normal([n_hidden_2]), name='bias2')\n",
    "layer_2 = tf.add(tf.matmul(layer_1, weight_2), bias_2, name='layer2')\n",
    "layer_2 = tf.nn.sigmoid(layer_2)\n",
    "\n",
    "weight_3 = tf.Variable(tf.random_normal([n_hidden_2, 2]))\n",
    "bias_3 = tf.Variable(tf.random_normal([2]))\n",
    "layer_3 = tf.add(tf.matmul(layer_2, weight_3), bias_3)\n",
    "layer_3 = tf.nn.sigmoid(layer_3)\n",
    "\n",
    "layer_4 = tf.nn.relu(tf.reduce_sum(layer_3, reduction_indices=0))\n",
    "\n",
    "\n",
    "# y_ = tf.placeholder(tf.float32, [None, 2])\n",
    "# cross_entropy = tf.reduce_mean(-tf.reduce_sum(y_ * tf.log(y), reduction_indices=[0]))\n",
    "# train_step = tf.train.GradientDescentOptimizer(0.5).minimize(cross_entropy)\n",
    "\n",
    "# print x.get_shape()\n",
    "# print weight_1.get_shape()\n",
    "# print layer_1.get_shape()\n",
    "# print layer_3.get_shape()\n",
    "# print layer_4.get_shape()\n",
    "cost = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(layer_4, y))\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate).minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cost value: 0.754472\n",
      "cost value: 0.693087\n",
      "cost value: 0.69373\n",
      "cost value: 0.694117\n",
      "cost value: 0.692338\n",
      "cost value: 0.691239\n",
      "cost value: 0.692768\n",
      "cost value: 0.67142\n",
      "cost value: 0.853824\n",
      "cost value: 0.493681\n",
      "[array([  1.14170063e+00,   8.43278322e-05], dtype=float32)] [1, 0]\n",
      "Total Accuracy: 0.86746\n"
     ]
    }
   ],
   "source": [
    "# Initializing the variables\n",
    "init = tf.initialize_all_variables()\n",
    "\n",
    "# Launch the graph`\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    for i in range(10):\n",
    "        for i in range(1000):\n",
    "            batch_x, batch_y = next_batch(train_data, train_errors)\n",
    "            _o, _c = sess.run([optimizer, cost], feed_dict={x: batch_x, y: batch_y})\n",
    "        print  'cost value:', _c\n",
    "    \n",
    "    result = sess.run([layer_4], feed_dict={x: batch_x, y: batch_y })\n",
    "    print result, batch_y\n",
    "    \n",
    "    # Test model\n",
    "    correct_prediction = tf.equal(tf.argmax(layer_4, 0), tf.argmax(y, 0))\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, \"float\"))\n",
    "    \n",
    "    total_accuracy = 0\n",
    "    for i in range(50):\n",
    "        for i in range(1000):\n",
    "            batch_x, batch_y = next_batch(test_data, test_errors)\n",
    "            total_accuracy += accuracy.eval({x: batch_x, y: batch_y})\n",
    "    \n",
    "    print 'Total Accuracy:', total_accuracy/50000.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
