{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Slection vs Feature Extraction \n",
    "\n",
    "Dimensionality Reduction에는 2가지 종류의 스킬이 있습니다. \n",
    "\n",
    "1. Feature Selection: original features의 일부분 (subset)을 선택합니다. \n",
    "2. Feature Extraction: original features에서 중요한 정보를 꺼내서 **새로운** feature subspace를 만듭니다.\n",
    "\n",
    "<img src=\"images/selection_vs_extraction.png\">\n",
    "\n",
    "기본적으로 Feature Selection은 4가지가 있습니다. \n",
    "\n",
    "1. **Sequential Foward Selection (SFS)**\n",
    "2. **Sequential Backward Selection (SBS)**\n",
    "3. **Sequential Floating Forward Selection (SFFS)**\n",
    "4. **Sequential Floating Backward Selection (SFBS)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sequential Feature Selection Algorithm\n",
    "\n",
    "Sequential Feature Selection Algorithm은 greedy search algorithm으로서 <br>\n",
    "d-dimensional feature space를 k-dimensional feature subspace로 바꿔줍니다. <br>\n",
    "이때 k < d 라는 조건을 갖습니다.\n",
    "\n",
    "**특히 regularization을 지원하지 않는 알고리즘에 사용이 될 수 있는 장점이 있습니다. **\n",
    "\n",
    "특히 Model이 overfitting을 겪을 경우, Sequential Backward Selection (SBS)같은 알고리즘이.. <br>\n",
    "간혹 prediction수치 자체를 높이는 경우도 있습니다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Selection Definition\n",
    "\n",
    "$ X = \\{ x_i\\; |\\; i=1...N \\} $ 이 주어졌을때 subset $ Y_M = \\{ x_{i_1}, x_{i_2}, ..., x_{i_M} \\} $ 을 찾습니다. <br>\n",
    "이때 $ M < N $ 이며 $ x_i \\in  X $ 입니다.\n",
    "\n",
    "$$ \\begin{bmatrix} x_1 \\\\ x_2 \\\\ . \\\\ . \\\\ . \\\\ x_N \\end{bmatrix} \\rightarrow feature\\ selection \\rightarrow \\begin{bmatrix} x_{i_1} \\\\ x_{i_2} \\\\ \\\\ x_{i_M}  \\end{bmatrix} $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%pylab inline\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# Set Random Seed\n",
    "np.random.seed(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wine Data\n",
    "\n",
    "* [https://archive.ics.uci.edu/ml/datasets/Wine](https://archive.ics.uci.edu/ml/datasets/Wine)\n",
    "\n",
    "\n",
    "1. Alcohol \n",
    "2. Malic acid \n",
    "3. Ash \n",
    "4. Alcalinity of ash \n",
    "5. Magnesium \n",
    "6. Total phenols \n",
    "7. Flavanoids \n",
    "8. Nonflavanoid phenols \n",
    "9. Proanthocyanins \n",
    "10. Color intensity \n",
    "11. Hue \n",
    "12. OD280/OD315 of diluted wines \n",
    "13. Proline \n",
    "\n",
    "\n",
    "**Classes**\n",
    "\n",
    "1. class 1: 59\n",
    "2. class 2: 71\n",
    "3. class 3: 48\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train X: (133, 13)\n",
      "Train Y: (133, 1)\n",
      "Test  X: (45, 13)\n",
      "Test  Y: (45, 1)\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('../../data/wine/wine_data.csv')\n",
    "\n",
    "X = data.iloc[:, 1:]\n",
    "Y = data.iloc[:, :1]\n",
    "\n",
    "# Standardization \n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "\n",
    "# Split Train and Test Data\n",
    "train_X, test_X, train_Y, test_Y = train_test_split(X, Y, test_size=0.25, random_state=1)\n",
    "\n",
    "print('Train X:', train_X.shape)\n",
    "print('Train Y:', train_Y.shape)\n",
    "print('Test  X:', test_X.shape)\n",
    "print('Test  Y:', test_Y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sequential Backward Selection (SBS)\n",
    "\n",
    "SBS알고리즘은 지정한 갯수의 features들을 뽑을때까지 계속 feature를 지워나가는 형태입니다. <br>\n",
    "이를 위해서 **Criterion function J**를 정의해야 합니다. \n",
    "\n",
    "\n",
    "**Input:** <br>\n",
    "$ X_d $ 에서 d값은 전체 the dimensionality of the full feature space를 나타냅니다.\n",
    "\n",
    "**Output:**<br>\n",
    "$ X_k $ 에서 k값은 subset feature의 갯수 이며, $ k < d $ 입니다.\n",
    "\n",
    "**Initialization**<br>\n",
    "$ k = d $ 로 시작을 합니다.\n",
    "\n",
    "**Execution**<br>\n",
    "특정 feature $ x^- $ 지정하고 criterion function J통해서 가장 적은 performance(accurace)를 보이는 feature를 삭제 합니다.<br>\n",
    "즉 하나하나씩 각각의 feature들을 다 돌아보며.. 가장 적게 accuracy를 보이는 녀석을 1개씩 삭제시켜나가는 것입니다. \n",
    "\n",
    "$$ x^- = argmax\\ J(X_k -x) $$\n",
    "\n",
    "criterion function J를 maximize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class SequentialBackwardSelection(object):\n",
    "    def fit(self, X, y):\n",
    "        pass\n",
    "\n",
    "sbs = SequentialBackwardSelection()\n",
    "sbs.fit(train_X, train_Y)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
