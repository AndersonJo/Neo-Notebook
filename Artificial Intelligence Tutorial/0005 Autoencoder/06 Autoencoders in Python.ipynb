{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Autoencoder in Python\n",
    "\n",
    "Python Numpy를 이용해서 Autoencoder를 구현합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%pylab inline\n",
    "import numpy as np\n",
    "from keras.datasets import mnist\n",
    "import sympy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Compression via Autoencoders\n",
    "\n",
    "예를 들어서 모바일 데이터를 클라우드로 보내려고 합니다.<br>\n",
    "이때 데이터는 다음과 같은 좌표로 구성이 되어 있으며, 눈으로 보면 알수 있듯이 x에 비해서 y값이 2배이상 빠르게 증가하는것을 알 수 있습니다.\n",
    "\n",
    "<img src=\"images/autoencoder01.png\" class=\"img-responsive img-rounded\">\n",
    "\n",
    "즉 이러한 관계를 이용하여, 데이터의 1 dimension만 클라우드로 보낸다면 데이터의 양을 compress할 수 있을 것입니다. <br>\n",
    "클라우드에서는 받은 데이터를 2배정도 증가시켜서 대략의 데이터값을 복원할 수 있습니다. \n",
    "\n",
    "1. **Encoding**: $ x^{(i)} $ data의 compress 해서 $ z^{(i)} $ data로 변환시킵니다.\n",
    "2. **Sending**: $ z^{(i)} $를 클라우드로 보냅니다.\n",
    "3. **Decoding**: $ z^{(i)}$ 데이터를  $ \\hat{x}^{(i)} $ 로 변환시킵니다.\n",
    "\n",
    "### $$ z^{(i)} = W_1  x^{(i)} + b_1$$\n",
    "\n",
    "### $$ \\hat{x}^{(i)} = W_2 z^{(i)} + b_2 $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Autoencoder는 2개의 부분으로 이루어져 있습니다. <br>\n",
    "Encoder 부분은 $ \\textit{h} = f(x) $ 그리고 Decoder부분으로 $ r = g(h) $<br>\n",
    "x -> hidden layer -> reconstruction\n",
    "\n",
    "<img src=\"images/autoencoder_layer.png\" class=\"img-responsive img-rounded\">\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Undercomplete\n",
    "\n",
    "x에서 reconstruction으로 copy하는 수준인데.. 이게 대체 왜 필요한가에 대한 의문이 들 것입니다.<br>\n",
    "실제로 reconstruction layer를 사용하는 경우보다는 hidden layer에 주목할 필요가 있습니다. \n",
    "\n",
    "hidden layer를 x보다 더 작은 dimension으로 제약을 줌으로서 여기서 사용할만한 feature 정보를 얻을수 있습니다. <br>\n",
    "이렇게 hidden layer가 x보다 작게하는 방법을 **undercomplete**라고 하며<br>\n",
    "이때 데이터를 줄임으로서 x의 아주 중요한 features 정보들만 저장할수 있게 됩니다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cost function\n",
    "\n",
    "Gradient descent를 활용하기 위해서 sum of sqaured error (SSE)를 사용합니다.\n",
    "\n",
    "### $$ \\sum^m_{i=1} \\left( \\hat{x}^{(i)} - x^{(i)} \\right)  $$\n",
    "\n",
    "###  $$ = \\sum^m_{i=1} \\left( W_2 z^{(i)} + b_2 - x^{(i)} \\right)  $$\n",
    "\n",
    "###  $$ = \\sum^m_{i=1} \\left( W_2 (W_1  x^{(i)} + b_1) + b_2 - x^{(i)} \\right)  $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Backpropagation & Weight Update\n",
    "\n",
    "아래의 공식은 weight update하는 공식\n",
    "\n",
    "$$ w_1 = \\Delta w_1 + w_1 $$\n",
    "\n",
    "weight change를 구하는 공식은 아래에 있습니다.<br>\n",
    "* $ \\eta $ 는 learning rate\n",
    "* $ \\| x \\|^2 $ 는 norm2 를 뜻함\n",
    "* $ \\frac{1}{2} $ 는 derivation 할때 쉽게 하기 위해서 붙음\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "$$ \\Delta w_1 = - \\eta \\cdot \\frac{\\partial}{\\partial w_1} \\frac{1}{2} \\| x - \\hat{x} \\|^2  $$\n",
    "\n",
    "$$ \\Delta w_1 = -\\eta \\cdot \\frac{\\partial}{\\partial w_1} \\frac{1}{2} \\sum^m_{i=1} (x - \\hat{x})^2 $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train x Shape: (60000, 28, 28)\n",
      "Test x Shape: (10000, 28, 28)\n",
      "\n",
      "[After Reshaping]\n",
      "Train x Shape: (60000, 784)\n",
      "Test x Shape: (10000, 784)\n"
     ]
    }
   ],
   "source": [
    "(train_x, train_y), (test_x, test_y) = mnist.load_data()\n",
    "train_x = train_x.astype('float32')/255.\n",
    "test_x = test_x.astype('float32')/255.\n",
    "\n",
    "print('Train x Shape:', train_x.shape)\n",
    "print('Test x Shape:', test_x.shape)\n",
    "\n",
    "# Reshape\n",
    "train_x = train_x.reshape((len(train_x), np.prod(train_x.shape[1:]))) # (60000, 28*28=784))\n",
    "test_x = test_x.reshape((len(test_x), np.prod(test_x.shape[1:]))) # (60000, 28*28=784))\n",
    "\n",
    "print('\\n[After Reshaping]')\n",
    "print('Train x Shape:', train_x.shape)\n",
    "print('Test x Shape:', test_x.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Autoencoder in Python "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class Autoencoder(object):\n",
    "    def __init__(self, input_dim=784, encoding_dim=32, batch_size=50):\n",
    "        self.batch_size = batch_size\n",
    "        self.input_w = np.random.rand(batch_size, input_dim + 1) # (50, 784+1) 이미지 받기\n",
    "        self.encoded_w = np.random.rand(batch_size, encoding_dim + 1) # (50, 32+1) Compressed\n",
    "        self.output_w = np.random.rand(encoding_dim, input_dim) # (32, 784) 복원\n",
    "        self.output_b = np.random.rand(batch_size)\n",
    "    \n",
    "    def train(self, X, nb_epoch=50, eta=0.01):\n",
    "        N = len(X)\n",
    "        \n",
    "        for epoch in range(nb_epoch):\n",
    "            for step in range(int(N/self.batch_size)):\n",
    "                samples = self.get_batch(X, N)\n",
    "\n",
    "                # Forward Propagation\n",
    "                encoded = self.encode(samples) # (32, 50)\n",
    "                decoded = self.decode(encoded) # (32, 784)\n",
    "\n",
    "                # Back Propagation\n",
    "                samples - decoded\n",
    "                break\n",
    "            \n",
    "            break\n",
    "                \n",
    "    def get_batch(self, X, N):\n",
    "        indices = np.random.randint(0, N, size=self.batch_size)\n",
    "        return X[indices]\n",
    "    \n",
    "    def encode(self, data):\n",
    "        encoded_input = self.input_w[:, 1:].dot(data.T) + self.input_w[:, 0] # (50, 50)\n",
    "        return self.sigmoid(self.encoded_w[:, 1:].T.dot(encoded_input) + self.encoded_w[:, 0]) # (32, 50)\n",
    "    \n",
    "    def decode(self, data):\n",
    "        decoded = (data.T.dot(self.output_w).T + self.output_b).T\n",
    "        return self.sigmoid(decoded)  # (50, 784)\n",
    "    \n",
    "    def relu(self, data):\n",
    "        return np.maximum(data, 0)\n",
    "    \n",
    "    def sigmoid(self, data):\n",
    "        return 1./(1. + np.exp(-data))\n",
    "    \n",
    "    def desigmoid(self, data):\n",
    "        return 1(-data) * data\n",
    "    \n",
    "    def norm2(self, data):\n",
    "        return data/np.sqrt(np.sum(data**2))\n",
    "        \n",
    "autoencoder = Autoencoder()\n",
    "autoencoder.train(train_x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### References\n",
    "\n",
    "[Autoencoder - Xiaogang Wang](https://piazza-resources.s3.amazonaws.com/i48o74a0lqu0/i64w68xz4oe4sa/deep_learning.pdf?AWSAccessKeyId=AKIAIEDNRLJ4AZKBW6HA&Expires=1483614971&Signature=tsrGbBBAQMsNfPOEImqhjp6IAQw%3D)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
