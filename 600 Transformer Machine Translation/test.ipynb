{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2fc7573a-4009-4a13-bc5c-d6fff63e8c78",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-02T08:47:15.233861633Z",
     "start_time": "2024-03-02T08:47:14.384960581Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "True"
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "import sentencepiece as spm\n",
    "import torch.nn as nn\n",
    "\n",
    "sp = spm.SentencePieceProcessor()\n",
    "sp.load(\"sp-bpt-anderson.model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3e1709ee51b0d14",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "63e4b314-77e7-4815-852b-1d30ffdb9e79",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-02T08:47:20.713633735Z",
     "start_time": "2024-03-02T08:47:19.508139792Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "from model import TransformerModule\n",
    "\n",
    "max_seq_len = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "22d579b47ff666d8",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-02T08:47:20.724138374Z",
     "start_time": "2024-03-02T08:47:20.717164995Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "True"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sentencepiece as spm\n",
    "\n",
    "sp = spm.SentencePieceProcessor()\n",
    "sp.load(\"sp-bpt-anderson.model\")"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "TransformerModule(\n  (src_embedding): Embedding(8000, 256)\n  (tgt_embedding): Embedding(8000, 256)\n  (positional_encoding): PositionalEncoding(\n    (dropout): Dropout(p=0.1, inplace=False)\n  )\n  (transformer_encoder): TransformerEncoder(\n    (layers): ModuleList(\n      (0-5): 6 x TransformerEncoderLayer(\n        (self_attn): MultiheadAttention(\n          (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)\n        )\n        (linear1): Linear(in_features=256, out_features=2048, bias=True)\n        (dropout): Dropout(p=0.1, inplace=False)\n        (linear2): Linear(in_features=2048, out_features=256, bias=True)\n        (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n        (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n        (dropout1): Dropout(p=0.1, inplace=False)\n        (dropout2): Dropout(p=0.1, inplace=False)\n      )\n    )\n  )\n  (transformer_decoder): TransformerDecoder(\n    (layers): ModuleList(\n      (0-5): 6 x TransformerDecoderLayer(\n        (self_attn): MultiheadAttention(\n          (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)\n        )\n        (multihead_attn): MultiheadAttention(\n          (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)\n        )\n        (linear1): Linear(in_features=256, out_features=2048, bias=True)\n        (dropout): Dropout(p=0.1, inplace=False)\n        (linear2): Linear(in_features=2048, out_features=256, bias=True)\n        (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n        (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n        (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n        (dropout1): Dropout(p=0.1, inplace=False)\n        (dropout2): Dropout(p=0.1, inplace=False)\n        (dropout3): Dropout(p=0.1, inplace=False)\n      )\n    )\n  )\n  (out): Linear(in_features=256, out_features=8000, bias=True)\n)"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_path = (\n",
    "    \"checkpoints/machine-translation-mode=1.0-epoch=94-step=415625-loss=1.9441.ckpt\"\n",
    ")\n",
    "model = TransformerModule.load_from_checkpoint(model_path)\n",
    "model.eval()\n",
    "model.to(\"cuda\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-02T08:47:30.771056685Z",
     "start_time": "2024-03-02T08:47:29.194289066Z"
    }
   },
   "id": "e884bea1e2132e66",
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3033/3631070010.py:85: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(seq == pad_idx).to(seq.device)\n"
     ]
    },
    {
     "data": {
      "text/plain": "['I will tell you the story of my vacation this summer vacation.',\n 'Would you like me to help you?',\n 'Please give me money.',\n \"I'm reading Harry Potter.\"]"
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from sentencepiece import SentencePieceProcessor\n",
    "from torch import nn\n",
    "\n",
    "from model import TransformerModule\n",
    "from typing import Optional, List\n",
    "\n",
    "class BeamSearch:\n",
    "\n",
    "    def __init__(self, model: TransformerModule, sp: SentencePieceProcessor, device: Optional[str] = None,\n",
    "                 max_seq_len: int = 128):\n",
    "        self.model = model\n",
    "        self.sp = sp\n",
    "        self.max_seq_len = max_seq_len\n",
    "        self.device = device if device else torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    def greedy_search_from_text(self, text):\n",
    "        self.model.eval()\n",
    "        self.model.to(self.device)\n",
    "\n",
    "        src_tensor = self.create_source_tensor(text)\n",
    "        src_padding_mask = self.get_padding_mask(src_tensor, pad_idx=self.sp.pad_id())\n",
    "        return self.greedy_search(src_tensor, src_padding_mask)\n",
    "        \n",
    "    def greedy_search(self, src_tensor: torch.Tensor, src_padding_mask: torch.Tensor):\n",
    "        batch_size = src_tensor.shape[0]\n",
    "        # Get initial encoder output\n",
    "        # if we wrap it with `torch.no_grad()` it doesn't work for some reason.\n",
    "        with torch.enable_grad():\n",
    "            memory = self.model.encode(src_tensor, src_padding_mask=src_padding_mask)\n",
    "            memory = memory.to(self.device)\n",
    "            mask = torch.zeros(batch_size).type(torch.bool).to(self.device)\n",
    "            \n",
    "        with torch.no_grad():\n",
    "            # Create decoder input.\n",
    "            # it starts with <bos> token.\n",
    "            y_pred = (\n",
    "                torch.ones(batch_size, 1)\n",
    "                .fill_(self.sp.bos_id())\n",
    "                .type(torch.long)\n",
    "                .to(self.device)\n",
    "            )\n",
    "            \n",
    "            for i in range(self.max_seq_len - 1):\n",
    "                tgt_mask = (nn.Transformer.generate_square_subsequent_mask(y_pred.size(1))\n",
    "                            .type(torch.bool).to(self.device))\n",
    "                out = self.model.decode(y_pred, memory, tgt_mask)\n",
    "                prob = self.model.out(out[:, -1])\n",
    "                _, next_words = torch.max(prob, dim=1)\n",
    "                \n",
    "                y_pred = torch.cat(\n",
    "                    [y_pred, \n",
    "                     next_words.masked_fill(mask, self.sp.pad_id()).type_as(src_tensor.data).unsqueeze(1)], dim=1).to(self.device)\n",
    "                \n",
    "                mask |= next_words == self.sp.eos_id()\n",
    "                if mask.all().item():\n",
    "                    break\n",
    "                    \n",
    "        return y_pred, prob\n",
    "\n",
    "    def convert_output_to_text(self, y_pred: torch.Tensor):\n",
    "        batch_size = y_pred.shape[0]\n",
    "        output = [None] * batch_size\n",
    "        for i in range(batch_size):\n",
    "            output[i] = self.sp.Decode(y_pred[i].tolist())\n",
    "        return output\n",
    "\n",
    "    def create_source_tensor(self, texts: List[str]) -> torch.Tensor:\n",
    "        # Create src input\n",
    "        batch_size = len(texts)\n",
    "        src_tensor = torch.zeros(batch_size, self.max_seq_len, dtype=torch.int32).to(self.model.device)\n",
    "        \n",
    "        for i, text in enumerate(texts):\n",
    "            src_tokenized = self.sp.Encode(text, add_bos=True, add_eos=True)\n",
    "            src_tokenized = src_tokenized[:self.max_seq_len]\n",
    "            if src_tokenized[-1] != self.sp.eos_id():\n",
    "                src_tokenized[-1] = self.sp.eos_id()\n",
    "            \n",
    "            src_tensor[i, :len(src_tokenized)] = torch.Tensor(src_tokenized)\n",
    "        src_tensor = src_tensor.to(self.device)\n",
    "        return src_tensor\n",
    "\n",
    "    @staticmethod\n",
    "    def get_padding_mask(seq, pad_idx: int):\n",
    "        return torch.tensor(seq == pad_idx).to(seq.device)\n",
    "\n",
    "\n",
    "search = BeamSearch(model, sp)\n",
    "y_pred, y_prob = search.greedy_search_from_text([\"제가 이번 여름 휴가 보낸 이야기를 할게요.\", \"도와드릴까요??\", \"돈 줘\", \"해리포터 읽고 있어요\"])\n",
    "search.convert_output_to_text(y_pred)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-02T09:20:17.611886644Z",
     "start_time": "2024-03-02T09:20:17.555231217Z"
    }
   },
   "id": "f365ba1f01690b5e",
   "execution_count": 32
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from beam_search import BeamSearch\n",
    "\n",
    "\n",
    "search = BeamSearch(model, sp)\n",
    "search.greedy_search(\"제가 이번 여름 휴가 보낸 이야기를 할게요.\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "deed84e660574385"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "text = \"제가 이번 여름 휴가 보낸 이야기를 할게요.\"\n",
    "src_tokenized = sp.encode(text, add_bos=True, add_eos=True)\n",
    "\n",
    "src_tokenized = src_tokenized[:max_seq_len]\n",
    "if src_tokenized[-1] != sp.eos_id():\n",
    "    src_tokenized[-1] = sp.eos_id()\n",
    "\n",
    "src_tensor = torch.zeros(max_seq_len, dtype=torch.int32).to(model.device)\n",
    "src_tensor[: len(src_tokenized)] = torch.tensor(src_tokenized)\n",
    "src_tensor = src_tensor.unsqueeze(0)\n",
    "\n",
    "src_padding_mask = get_padding_mask(src_tensor, pad_idx=sp.pad_id())\n",
    "\n",
    "print(f\"src_tensor:\", src_tensor.shape, src_tensor)\n",
    "print(f\"tgt_input :\", tgt_input.shape, tgt_input)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6e54b8cc8dc8f2e8"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    # tgt_idx = 1\n",
    "    # tgt_padding_mask = get_padding_mask(tgt_input[:, :tgt_idx], pad_idx=sp.pad_id())\n",
    "    # tgt_mask = nn.Transformer.generate_square_subsequent_mask(tgt_idx, device='cuda')\n",
    "\n",
    "    memory = model.encode(src=src_tensor, src_padding_mask=src_padding_mask)\n",
    "    \n",
    "    # output = model(\n",
    "    #     src_tensor,\n",
    "    #     tgt_input[:, :tgt_idx],\n",
    "    #     src_padding_mask=src_padding_mask,\n",
    "    #     tgt_padding_mask=tgt_padding_mask,\n",
    "    #     tgt_mask=tgt_mask\n",
    "    # )\n",
    "\n",
    "    print(memory)\n",
    "    "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e1ace0d2364c21da"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "torch.max(output[0], dim=1)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b2e1927e0b158735"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "tgt_input"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "36f3662259f4811b"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "tgt_input = torch.zeros(max_seq_len, dtype=torch.int32).to(model.device)\n",
    "tgt_input[0] = sp.bos_id()\n",
    "tgt_input = tgt_input.unsqueeze(0)\n",
    "\n",
    "with torch.no_grad():\n",
    "    tgt_idx = 1\n",
    "    while True:\n",
    "        print(tgt_input[:, :tgt_idx][0].tolist())\n",
    "        tgt_mask = nn.Transformer.generate_square_subsequent_mask(tgt_idx, device='cuda').type(torch.bool)\n",
    "    \n",
    "        output = model.decode(tgt_input[:, :tgt_idx], memory, tgt_mask=tgt_mask)\n",
    "        output = model.out(output)\n",
    "        token_idx = torch.argmax(output[0][-1]).item()\n",
    "        tgt_input[:, tgt_idx] = token_idx\n",
    "        print(sp.decode(tgt_input[0].tolist()))\n",
    "        tgt_idx += 1\n",
    "\n",
    "        if token_idx == 3:\n",
    "            break\n",
    "        \n",
    "        \n",
    "    # print(torch.argmax(output[0][-1]))"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "be4addb77dfb65d9"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "\n",
    "def greedy_decode(model, src, src_padding_mask, max_len, start_symbol, device='cuda'):\n",
    "    \"\"\"\n",
    "    src: 인코더의 입력 문장, [batch_size, src_len]\n",
    "    src_mask: 소스 문장의 마스크, [batch_size, 1, src_len]\n",
    "    max_len: 생성할 최대 문장 길이\n",
    "    start_symbol: 문장 시작을 나타내는 심볼 (BOS 토큰)\n",
    "    \"\"\"\n",
    "    src = src.to(device)\n",
    "    src_padding_mask = src_padding_mask.to(device)\n",
    "\n",
    "    memory = model.encode(src, src_padding_mask=src_padding_mask)\n",
    "    ys = torch.ones(1, 1).fill_(start_symbol).type(torch.long).to(device)\n",
    "\n",
    "    for i in range(max_len-1):\n",
    "        memory = memory.to(device)\n",
    "        \n",
    "        tgt_mask = (nn.Transformer.generate_square_subsequent_mask(ys.size(1))\n",
    "                    .type(torch.bool)).to(device)\n",
    "        out = model.decode(ys, memory, tgt_mask)\n",
    "        out = out.transpose(0, 1)\n",
    "        prob = model.out(out[:, -1])\n",
    "        _, next_word = torch.max(prob, dim = 1)\n",
    "        \n",
    "        next_word = next_word[-1].item()\n",
    "\n",
    "        ys = torch.cat([ys,\n",
    "                        torch.ones(1, 1).type_as(src.data).fill_(next_word)], dim=1)\n",
    "\n",
    "        # print(sp.decode(ys[0].tolist()))\n",
    "        if next_word == 3:\n",
    "            break\n",
    "\n",
    "    return ys\n",
    "\n",
    "text = \"오랫동안 일부 사람들은 생명이 없는 물질로부터 생명이 발생할 수 있다고 믿었습니다.\"\n",
    "src_tokenized = sp.encode(text, add_bos=True, add_eos=True)\n",
    "\n",
    "src_tokenized = src_tokenized[:max_seq_len]\n",
    "if src_tokenized[-1] != sp.eos_id():\n",
    "    src_tokenized[-1] = sp.eos_id()\n",
    "\n",
    "src_tensor = torch.zeros(max_seq_len, dtype=torch.int32).to(model.device)\n",
    "src_tensor[: len(src_tokenized)] = torch.tensor(src_tokenized)\n",
    "src_tensor = src_tensor.unsqueeze(0)\n",
    "src_padding_mask = get_padding_mask(src_tensor, pad_idx=sp.pad_id())\n",
    "\n",
    "output = greedy_decode(model, src_tensor, src_padding_mask, max_len=128, start_symbol=sp.bos_id())\n",
    "\n",
    "print(sp.decode(output[0].tolist()))"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d66fa8d7c6d332c7"
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "f309ed28-6836-4745-9cf6-aec99a5a351e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TransformerModule(\n",
       "  (src_embedding): Embedding(8000, 256)\n",
       "  (tgt_embedding): Embedding(8000, 256)\n",
       "  (positional_encoding): PositionalEncoding(\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (transformer_encoder): TransformerEncoder(\n",
       "    (layers): ModuleList(\n",
       "      (0-5): 6 x TransformerEncoderLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)\n",
       "        )\n",
       "        (linear1): Linear(in_features=256, out_features=2048, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (linear2): Linear(in_features=2048, out_features=256, bias=True)\n",
       "        (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout1): Dropout(p=0.1, inplace=False)\n",
       "        (dropout2): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (transformer_decoder): TransformerDecoder(\n",
       "    (layers): ModuleList(\n",
       "      (0-5): 6 x TransformerDecoderLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)\n",
       "        )\n",
       "        (multihead_attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)\n",
       "        )\n",
       "        (linear1): Linear(in_features=256, out_features=2048, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (linear2): Linear(in_features=2048, out_features=256, bias=True)\n",
       "        (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout1): Dropout(p=0.1, inplace=False)\n",
       "        (dropout2): Dropout(p=0.1, inplace=False)\n",
       "        (dropout3): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (out): Linear(in_features=256, out_features=8000, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "c90dc4cfa89284e0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-12T16:05:57.529265650Z",
     "start_time": "2024-02-12T16:05:57.516588763Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1, 8000])\n"
     ]
    }
   ],
   "source": [
    "print(output.shape)\n",
    "tgt_input[:, 1] = torch.argmax(output[-1], dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "83743efb-c629-4d2e-a841-6bea36a5cb54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 2, 17,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "          0,  0]], device='cuda:0', dtype=torch.int32)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tgt_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "1f453f844a37afb4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-12T15:58:50.613047728Z",
     "start_time": "2024-02-12T15:58:50.571618495Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (3820642031.py, line 6)",
     "output_type": "error",
     "traceback": [
      "\u001B[0;36m  Cell \u001B[0;32mIn[56], line 6\u001B[0;36m\u001B[0m\n\u001B[0;31m    for i in range(max_len-1):\u001B[0m\n\u001B[0m                             ^\u001B[0m\n\u001B[0;31mSyntaxError\u001B[0m\u001B[0;31m:\u001B[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "def greedy_decode(model, src, max_len, start_symbol, device='cuda'):\n",
    "    src = src.to(device)\n",
    "\n",
    "    memory = model(src\n",
    "    ys = torch.ones(1, 1).fill_(start_symbol).type(torch.long).to(DEVICE)\n",
    "    for i in range(max_len-1):\n",
    "        memory = memory.to(DEVICE)\n",
    "        tgt_mask = (generate_square_subsequent_mask(ys.size(0))\n",
    "                    .type(torch.bool)).to(DEVICE)\n",
    "        out = model.decode(ys, memory, tgt_mask)\n",
    "        out = out.transpose(0, 1)\n",
    "        prob = model.generator(out[:, -1])\n",
    "        _, next_word = torch.max(prob, dim=1)\n",
    "        next_word = next_word.item()\n",
    "\n",
    "        ys = torch.cat([ys,\n",
    "                        torch.ones(1, 1).type_as(src.data).fill_(next_word)], dim=0)\n",
    "        if next_word == EOS_IDX:\n",
    "            break\n",
    "    return ys\n",
    "\n",
    "\n",
    "def translate(model, text, sp):\n",
    "    model.eval()\n",
    "    pad_idx = sp.pad_idx()\n",
    "    \n",
    "    src_tokenized = sp.encode(text, add_bos=True, add_eos=True)\n",
    "    if src_tokenized[-1] != sp.eos_id():\n",
    "        src_tokenized[-1] = sp.eos_id()\n",
    "        \n",
    "    src_tensor = torch.zeros(max_seq_len, dtype=torch.int32).to(model.device)\n",
    "    src_tensor[:len(src_tokenized)] = torch.tensor(src_tokenized)\n",
    "    src_tensor = src_tensor.unsqueeze(0)\n",
    "\n",
    "    src_padding_mask = get_padding_mask(src_tensor, pad_idx)\n",
    "\n",
    "    madel(src_tensor, src_padding_mask=src_padding_mask)\n",
    "\n",
    "    \n",
    "    \n",
    "    greedy_decode(model, src_tensor, max_len=128, start_symbol=sp.bos_idx())\n",
    "\n",
    "def get_padding_mask(seq, pad_idx:int):\n",
    "    torch.tensor(seq == pad_idx).to(seq.device)\n",
    "                  \n",
    "translate(model, '안녕! 내일 학교에서 보자! 내일은 돈 꼭 갚아!', sp=sp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "5612de2fbc6e164b",
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'int' object has no attribute 'device'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[49], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m \u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_make_padding_mask\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m4\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/projects/machine-learning/710 Transformer Machine Translation/model.py:64\u001B[0m, in \u001B[0;36m_make_padding_mask\u001B[0;34m(seq, pad_idx)\u001B[0m\n\u001B[1;32m     59\u001B[0m     memory \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtransformer_encoder(src\u001B[38;5;241m=\u001B[39msrc_pos_encoded, mask\u001B[38;5;241m=\u001B[39msrc_mask,\n\u001B[1;32m     60\u001B[0m                                       src_key_padding_mask\u001B[38;5;241m=\u001B[39msrc_padding_mask)\n\u001B[1;32m     61\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m memory\n\u001B[1;32m     63\u001B[0m \u001B[38;5;129m@staticmethod\u001B[39m\n\u001B[0;32m---> 64\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_make_padding_mask\u001B[39m(seq: torch\u001B[38;5;241m.\u001B[39mTensor, pad_idx: \u001B[38;5;28mint\u001B[39m) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m torch\u001B[38;5;241m.\u001B[39mTensor:\n\u001B[1;32m     65\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m torch\u001B[38;5;241m.\u001B[39mtensor(seq \u001B[38;5;241m==\u001B[39m pad_idx)\u001B[38;5;241m.\u001B[39mto(seq\u001B[38;5;241m.\u001B[39mdevice)\n\u001B[1;32m     67\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mtraining_step\u001B[39m(\u001B[38;5;28mself\u001B[39m, batch: Dict[\u001B[38;5;28mstr\u001B[39m, torch\u001B[38;5;241m.\u001B[39mTensor], batch_idx: \u001B[38;5;28mint\u001B[39m):\n",
      "\u001B[0;31mAttributeError\u001B[0m: 'int' object has no attribute 'device'"
     ]
    }
   ],
   "source": [
    "model._make_padding_mask(4, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96a51bce-7613-404c-a8f8-f31ad7e80f75",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyEnv 3.9.18",
   "language": "python",
   "name": "3.9.18"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
