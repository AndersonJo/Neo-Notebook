{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Binary String Classfication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "from tensorflow.contrib.rnn import RNNCell, BasicLSTMCell, MultiRNNCell, DropoutWrapper"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Interactive Session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "init_op = tf.global_variables_initializer()\n",
    "gpu_options = tf.GPUOptions(per_process_gpu_memory_fraction=0.001, allow_growth=True)\n",
    "sess = tf.InteractiveSession(config=tf.ConfigProto(gpu_options=gpu_options))\n",
    "sess.run(init_op)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "LABEL_SIZE = 100\n",
    "TRAINING_SIZE = 50000\n",
    "TEST_SIZE = 10000\n",
    "\n",
    "def create_data(size=50000, maximum=1000, end_token=2):\n",
    "    max_length = len(bin(maximum-1)[2:]) + 1\n",
    "    rands = np.random.randint(0, maximum, size=500000)\n",
    "    xs = np.zeros((size, 1, max_length), dtype='float32')\n",
    "    ys = np.zeros((size, 1, maximum), dtype='int32')\n",
    "    for i in range(size):\n",
    "        x = np.zeros(20, dtype='float32')\n",
    "        rand_bin = bin(rands[i])[2:]+ str(end_token)\n",
    "        rand_bin = list(map(float, list(rand_bin)))\n",
    "        xs[i, 0, :len(rand_bin)] = rand_bin    \n",
    "        ys[i, 0, rands[i]] = 1\n",
    "    \n",
    "    return xs, ys\n",
    "\n",
    "train_x, train_y = create_data(size=TRAINING_SIZE, maximum=LABEL_SIZE)\n",
    "test_x, test_y = create_data(size=TEST_SIZE, maximum=LABEL_SIZE)\n",
    "\n",
    "SENTENCE_LENGTH = train_x.shape[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50, 1, 8) (50, 1, 100)\n"
     ]
    }
   ],
   "source": [
    "def next_batch(x, y, size=50):\n",
    "    idx = np.random.randint(x.shape[0] - size)\n",
    "    return x[idx:idx+size], y[idx:idx+size]\n",
    "\n",
    "sample_x, sample_y = next_batch(train_x, train_y)\n",
    "print(sample_x.shape, sample_y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "hidden_size = 5\n",
    "\n",
    "with tf.variable_scope('test' + str(np.random.randint(0, 100000))):\n",
    "    inputs = tf.placeholder('float32', shape=[None, None, SENTENCE_LENGTH], name='inputs') # [batch, time, in]\n",
    "    targets = tf.placeholder('float32', shape=[None, None, LABEL_SIZE], name='targets') # [batch, time, out]\n",
    "    \n",
    "    cell = BasicLSTMCell(LABEL_SIZE, forget_bias=1.0, state_is_tuple=True)\n",
    "#     cell = DropoutWrapper(cell)\n",
    "    init_state = cell.zero_state(1, 'float32')\n",
    "\n",
    "    rnn_outputs, rnn_states = tf.nn.dynamic_rnn(cell, inputs, initial_state=init_state, time_major=True)\n",
    "#     rnn_outputs = tf.reshape(rnn_outputs, [-1, hidden_size])\n",
    "    \n",
    "#     w = tf.get_variable('weights', [hidden_size, 1], initializer=tf.random_normal_initializer())\n",
    "#     b = tf.get_variable('biases', [1, 1], initializer=tf.constant_initializer())\n",
    "    \n",
    "#     dense1 = tf.matmul(rnn_outputs, w) + b\n",
    "#     dense2 = tf.reduce_sum(dense1, reduction_indices=[1])\n",
    "#     prediction = tf.nn.sigmoid(dense2)\n",
    "    \n",
    "    error2 = tf.square(targets - rnn_outputs)\n",
    "    error3 = tf.reduce_mean(error2, reduction_indices=[0]) \n",
    "    train_fn = tf.train.AdamOptimizer(learning_rate=0.01).minimize(error3)\n",
    "    \n",
    "init_op = tf.global_variables_initializer()\n",
    "sess.run(init_op)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0] cost: 0.6340201211571693\n",
      "[1] cost: 0.30096231620013714\n",
      "[2] cost: 0.16398536373674868\n",
      "[3] cost: 0.10415067917108536\n",
      "[4] cost: 0.07905111364275218\n"
     ]
    }
   ],
   "source": [
    "def train(x, y, n_epoch=5, batch_size=50):\n",
    "    \n",
    "    for epoch in range(n_epoch):\n",
    "        costs = []\n",
    "        for step in range(int(x.shape[0]/batch_size)):\n",
    "            sample_x, sample_y = next_batch(x, y, size=batch_size)\n",
    "            cost, _ = sess.run([error3, train_fn], \n",
    "                                   feed_dict={inputs: sample_x, targets: sample_y})\n",
    "            costs.append(np.sum(cost))\n",
    "\n",
    "    #         print('xxxxx', cost.shape)\n",
    "    #         print(cost)\n",
    "    #         break\n",
    "\n",
    "        cost = sum(costs)/float(step + 1)\n",
    "        print(f'[{epoch}] cost: {cost}')\n",
    "\n",
    "train(train_x, train_y)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "테스트 갯수: 10000, 맞은 갯수: 288\n",
      "accuracy: 0.0288\n"
     ]
    }
   ],
   "source": [
    "def evaluate(x, y):\n",
    "    test_size = x.shape[0]\n",
    "    DATA_LIMIT = 200\n",
    "    \n",
    "    n_correct = 0\n",
    "    global_step = 0\n",
    "    for i in range(0, test_size, DATA_LIMIT):\n",
    "        y_preds = sess.run(rnn_outputs, feed_dict={inputs: x[i:i+DATA_LIMIT]})\n",
    "\n",
    "        for j in range(DATA_LIMIT):\n",
    "            y_pred = np.argmax(y_preds[j, 0])\n",
    "            y_true = np.argmax(y[j, 0])\n",
    "            if y_pred == y_true:\n",
    "                n_correct += 1\n",
    "                \n",
    "            global_step += 1\n",
    "    \n",
    "#     n_correct = 0\n",
    "#     for i in range(test_size):\n",
    "#         y_pred = np.argmax(y_preds[i, 0])\n",
    "#         y_true = np.argmax(y[i, 0])\n",
    "#         if y_pred == y_true:\n",
    "#             n_correct += 1\n",
    "            \n",
    "    print(f'테스트 갯수: {test_size}, 맞은 갯수: {n_correct}')\n",
    "    print('accuracy:', n_correct/float(test_size))\n",
    "\n",
    "evaluate(test_x, test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 1, 8)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_x.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
