{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Single Neural Network (Perceptron)\n",
    "\n",
    "\n",
    "<img src=\"./images/single_layer.png\" >\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Input\n",
    "\n",
    "먼저 input의 weighted sum을 구합니다. <br>\n",
    "공식에 bias를 따로 $ b $로 잡았지만, 보통 weight의 첫번째 element는 bias로 사용합니다.\n",
    "\n",
    "\n",
    "$$ z = h(x; \\theta, b) = \\left[ \\sum^K_{i=1} w_i x_i \\right] + b = w^T x + b $$ \n",
    "\n",
    "\n",
    "** Derivative of the Weights **\n",
    "\n",
    "$$ \\frac{\\partial}{\\partial w} \\left[ w^T x + b \\right] = x$$\n",
    "\n",
    "\n",
    "** Derivative of the Bias **\n",
    "\n",
    "$$ \\frac{\\partial}{\\partial b} \\left[ w^T x + b \\right] = 1$$\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Activation Function\n",
    "\n",
    "$ \\phi $ 함수는 activation fuction을 나타내며 예제를 위해서 sigmoid function (or logistic function)을 사용하겠습니다.\n",
    "\n",
    "$$ \\phi(z; w) = \\frac{1}{1 + e^{-z}} $$\n",
    "\n",
    "**Derivative of the sigmoid function**은 다음과 같습니다.\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "\\dfrac{d}{dz} \\phi(z) &= \\dfrac{d}{dz} \\left[ \\dfrac{1}{1 + e^{-z}} \\right] & [1] \\\\\n",
    "&= \\dfrac{d}{dz} \\left( 1 + \\mathrm{e}^{-z} \\right)^{-1}  & [2]\\\\\n",
    "&= -(1 + e^{-z})^{-2}(-e^{-z}) & [3]\\\\\n",
    "&= \\dfrac{e^{-x}}{\\left(1 + e^{-z}\\right)^2} & [4]\\\\\n",
    "&= \\dfrac{1}{1 + e^{-z}\\ } \\cdot \\dfrac{e^{-z}}{1 + e^{-x}}  & [5]\\\\\n",
    "&= \\dfrac{1}{1 + e^{-z}\\ } \\cdot \\dfrac{(1 + e^{-z}) - 1}{1 + e^{-z}}  & [6]\\\\\n",
    "&= \\dfrac{1}{1 + e^{-z}\\ } \\cdot \\left( 1 - \\dfrac{1}{1 + e^{-z}} \\right) & [7]\\\\\n",
    "&= \\phi(z) \\cdot (1 - \\phi(z)) & [8]\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "* [3] Chain Rule을 적용\n",
    "* [4] $ \\frac{d}{dx} e^{-z} = -e^{-z} $  이며  $ \\frac{d}{dx} e^{z} = e^{z} $"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Cost Function \n",
    "\n",
    "먼저 예제로서 **Object function** $ J(w) $ 를 정의합니다.<br>\n",
    "이때 $ \\phi(z^{(i)}) $ 는 activation function 입니다.\n",
    "\n",
    "$$ \\begin{align} \n",
    "J(w) &= \\frac{1}{N} \\sum_i \\left( y^{(i)} - \\phi(z^{(i)}) \\right)^2 \\\\\n",
    "\\end{align} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Stochastic Gradient Descent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Calculate Gradient with regard to weights \n",
    "\n",
    "먼저 Feedforward 순서도를 그리면 다음과 같습니다.\n",
    "\n",
    "$$ J(\\phi(h(x))) $$\n",
    "\n",
    "즉.. J는 mean squared error function, $ \\phi $는 sigmoid function, 그리고 h 는 $ w^T x + b $ 입니다.<br>\n",
    "이런식으로 함수 안에 다른 함수가 사용되는 부분은 chain rule로 derivation을 할수 있습니다.\n",
    "\n",
    "Optimization 문제는 objective function을 minimize 또는 maximize하는데 있습니다. <br>\n",
    "SSE를 사용시 minimize해야 하며, learning은  stochastic gradient descent를 통해서 처리를 하게 됩니다.\n",
    "\n",
    "$$ \\frac{\\partial J}{\\partial w_i} = \n",
    "\\frac{\\partial J}{\\partial \\hat{y}} \\cdot \n",
    "\\frac{\\partial \\hat{y}}{\\partial z } \\cdot\n",
    "\\frac{\\partial z}{\\partial w_i } \n",
    "$$\n",
    "\n",
    "즉 다음과 같다고 할 수 있습니다. <br>\n",
    "\n",
    "> (예제로서 activation function은 sigmoid 사용, loss는 mean squared error 사용)<br>\n",
    "> Stochastic gradient를 사용함으로 $ \\sum $ 심볼은 제외 될 수 있습니다.\n",
    "\n",
    "$$ \\begin{align} \n",
    "\\frac{\\partial J}{\\partial w_i} &= \n",
    "\\frac{\\partial }{\\partial \\hat{y}} \\left[ \\frac{1}{N} \\sum_{i=1} \\left( y^{(i)} - \\hat{y}^{(i)}  \\right)^2 \\right] \\cdot\n",
    "\\frac{\\partial}{\\partial z} \\left[ \\frac{1}{1+e^{-z}} \\right] \\cdot\n",
    "\\frac{\\partial}{\\partial w} \\left[ w^T x^{(i)} + b \\right] & [1] \\\\\n",
    "&= -\\frac{2}{N} \\left[ \\sum_{i=1} \\left( y^{(i)} - \\hat{y}^{(i)} \\right) \\right] \\cdot\n",
    " \\left[ \\hat{y}^{(i)} \\cdot (1-\\hat{y}^{(i)}) \\right] \\cdot x^{(i)} & [2]\n",
    "\\end{align} $$\n",
    "\n",
    "* **[2]** 에서 derivative of the sigmoid function은 $ \\phi(z) \\cdot (1-\\phi(z)) $ 입니다.<br> 즉 $ \\phi(z) $는 $ \\hat{y}^{(i)} $으로 변경될 수 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Calculate Gradient with regard to bias \n",
    "\n",
    "다음과 같은 Chain Rule이 그려지게 됩니다.\n",
    "\n",
    "$$ \\frac{\\partial J}{\\partial b_i} = \n",
    "\\frac{\\partial J}{\\partial \\hat{y}} \\cdot \n",
    "\\frac{\\partial \\hat{y}}{\\partial z } \\cdot\n",
    "\\frac{\\partial z}{\\partial b_i } \n",
    "$$\n",
    "\n",
    "풀어쓰면 다음과 같은 식이 만들어지게 됩니다.<br>\n",
    "\n",
    "> (위와 마찬가지로 activation function은 sigmoid 사용, loss는 mean squared error 사용)<br>\n",
    "> Stochastic gradient를 사용함으로 $ \\sum $ 심볼은 제외 될 수 있습니다.\n",
    "\n",
    "$$ \\begin{align} \n",
    "\\frac{\\partial J}{\\partial w_i}  &=\n",
    "\\frac{\\partial }{\\partial \\hat{y}} \\left[ \\frac{1}{N} \\sum_{i=1} \\left( y^{(i)} - \\hat{y}^{(i)}  \\right)^2 \\right] \\cdot\n",
    "\\frac{\\partial}{\\partial z} \\left[ \\frac{1}{1+e^{-z}} \\right] \\cdot\n",
    "\\frac{\\partial}{\\partial w} \\left[ w^T x + b \\right] \\\\\n",
    "&= -\\frac{2}{N} \\left[ \\sum_{i=1} \\left( y^{(i)} - \\hat{y}^{(i)} \\right) \\right] \\cdot\n",
    " \\left[ \\hat{y}^{(i)} \\cdot (1-\\hat{y}^{(i)}) \\right] \\cdot 1\n",
    "\\end{align} $$\n",
    "\n",
    "* **[2]** 에서 derivative of the sigmoid function은 $ \\phi(z) \\cdot (1-\\phi(z)) $ 입니다.<br> 즉 $ \\phi(z) $는 $ \\hat{y}^{(i)} $으로 변경될 수 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Update Weights\n",
    "\n",
    "$ \\eta $ 는 learning rate 입니다.<br>\n",
    "\n",
    "$$ \\begin{align} \n",
    "\\Delta w &= - \\eta \\nabla J(w)  \\\\\n",
    "w &= w + \\Delta w\n",
    "\\end{align}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Backpropagation Algorithm\n",
    "\n",
    "* $ \\theta $ 는 neural network안의 모든 weights를 말합니다. \n",
    "* $ \\theta^{l}_{i, j} $ 는 l번째 weight를 가르킵니다.\n",
    "* layers의 인덱스는 1 (input), 2 (hidden), ... , L (output)을 가르킵니다.\n",
    "\n",
    "\n",
    "### [1] Feedforward\n",
    "Feedfoward Pass를 $ h^{(1)} $, $ h^{(2)} $, $ h^{(3)} $, ...., $ h^{(L)} $ 에 대해서 계산을 합니다.\n",
    "\n",
    "$$ \\begin{align}\n",
    "h^{(1)} &= x \\\\\n",
    "h^{(2)} &= \\phi \\left( \\left( \\theta^{(1)} \\right)^T h^{(1)} + b^{(1)} \\right)\\\\\n",
    " ... \\\\\n",
    "h^{(L-1)} &= \\phi \\left(  \\left( \\theta^{(L-2)} \\right)^T h^{(L-2)} + b^{(L-2)} \\right) \\\\\n",
    "h(x) = h^{(L)} &= \\phi \\left( \\left( \\theta^{(L-1)} \\right)^T h^{(L-1)} + b^{(L-1)} \\right)\n",
    "\\end{align} $$ \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### [2] output layer 에서의 계산\n",
    "마지막 output에서는 다음과 같은 계산을 해줍니다.\n",
    "\n",
    "$$ \\begin{align}\n",
    "\\frac{\\partial J}{\\partial \\theta^{(L)}} &= \n",
    "\\frac{\\partial J}{\\partial h^{(L)}} \\cdot \n",
    "\\frac{\\partial h^{(L)}}{\\partial h^{(L-1)} } \\cdot\n",
    "\\frac{\\partial h^{(L-1)}}{\\partial \\theta^{(L)} } \n",
    "\\end{align} $$\n",
    "\n",
    "$$ \\begin{align}\n",
    "\\frac{\\partial J}{\\partial \\theta^{(L)}} = \\delta^{(L)} &=  \n",
    "\\frac{\\partial}{\\partial h^{(L)}} \\left[ \\frac{1}{N}  \\sum_{i=1} \\left( h^{(L)} - y^{(i)} \\right)^2 \\right] \\cdot\n",
    "\\frac{\\partial}{\\partial h^{(L-1)}} \\left[ \\frac{1}{1-e^{-h^{(L-1)}}} \\right] \\cdot\n",
    "\\frac{\\partial}{\\partial \\theta^{(L-1)}} \\left[ \\left( \\theta^{(L-1)} \\right)^T h^{(L-1)} + b^{(L-1)} \\right] & [1] \\\\\n",
    "&= \\frac{2}{N} \\left[ \\sum \\left( h^{(L)} - y^{(i)} \\right) \\right] \\odot \\phi^{\\prime} \\left( (\\theta^{(L-1)})^T h^{(L-1)} + b^{(L-1)} \\right) & [2] \\\\\n",
    "&= \\frac{2}{N} \\left[ \\sum \\left( h^{(L)} - y^{(i)} \\right) \\right] \\odot h^{(L)} (1- h^{(L)}) \\cdot h^{(L-1)} & [3]\n",
    "\\end{align} $$\n",
    "\n",
    "* **[1]** $ \\frac{1}{N}\\sum $ 부분에서 N을 2값으로 변경하여 ($ \\frac{1}{2} \\sum $) 계산 효율을 높일수 있습니다. \n",
    "* **[2]** 전형적인 output derivation공식입니다.\n",
    "* **[3]** $ \\phi $ 함수에 derivative of the sigmoid function $ \\phi(z)(1-\\phi(z)) $를 적용했을때 입니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### [3] L-1 부터의 계산\n",
    "\n",
    "$ l =  L -1, L -2, L -3 $, ... 부터 다음과 같은 계산을 합니다.<br>\n",
    "\n",
    "> sigmoid, mean squared error 사용한 예제 입니다.\n",
    "\n",
    "$$ \\begin{align}\n",
    "\\delta^{(l)} &= \\left[ \\left( \\theta^{(l)} \\right)^T \\delta^{(l+1)} \\right] \\odot \\phi^{\\prime} \\left( \\left( \\theta^{(l-1)} \\right)^T h^{(l-1)} + b^{(l-1)} \\right) & [1] \\\\\n",
    "&= \\left[ \\left( \\theta^{(l)} \\right)^T \\delta^{(l+1)} \\right] \\odot h^{(l)}(1-h^{(l)}) \\cdot h^{(l-1)} & [2]\n",
    "\\end{align} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### [4] Update\n",
    "\n",
    "$$ \\begin{align} \n",
    "\\Delta \\theta^{(l)} &= \\delta^{(l+1)} \\left( h^{(l)} \\right)^T \\\\\n",
    "\\Delta b^{(l)} &=  \\delta^{(l+1)}\n",
    "\\end{align} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# References \n",
    "\n",
    "* [Deep Learning Basics: Neural Networks, Backpropagation and Stochastic Gradient Descent](http://alexminnaar.com/deep-learning-basics-neural-networks-backpropagation-and-stochastic-gradient-descent.html)\n",
    "* [A Tutorial on Deep Learning Part 1: Nonlinear Classifiers and The Backpropagation Algorithm](https://cs.stanford.edu/~quocle/tutorial1.pdf)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
