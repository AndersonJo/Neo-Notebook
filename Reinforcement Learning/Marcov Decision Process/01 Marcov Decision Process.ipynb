{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Marcov Property\n",
    "\n",
    "**Marcov Property**를 갖었다는 것은 현재의 state, action만으로 (이전 과거의 state, action, reward에 대한 정보없이) 그 다음의  state, reward를 예측할수 있는 것을 말합니다.\n",
    "\n",
    "$$ Pr\\{ s_{t+1} = s^{\\prime}, r_{t+1} = r \\ | \\ s_t, a_t \\} $$\n",
    "\n",
    "예를 들어서 체스게임중의 특정 state는 marcov property 그리고 marcov state를 갖었습니다.<br>\n",
    "왜냐하면 현재의 게임 상황만을 봐도 (이전 과거 없이) 다음 수를 예측할수 있기 때문입니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transition Probability\n",
    "\n",
    "state와 action이 주어졌을때, 그 다음 나올 수 있는 next state $ s^{\\prime} $의 확률은 아래의 transition probability와 같습니다.<br>\n",
    "즉 현재의 체스 state와 어디에 말을 둘지 action에 대한 정보를 transition probability로 구하면 다음 state를 예측할 수 있습니다.\n",
    "\n",
    "### $$ T = Pr\\{ s_{t+1} = s^{\\prime} \\ | \\ s_t = s, a_t = a \\} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Expected Reward\n",
    "\n",
    "$$ R = E\\{ r_{t+1} \\ | \\ s_t=s, a_t =a, s_{t+1} =s^{\\prime} \\} $$"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
