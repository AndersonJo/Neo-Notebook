{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Markov Decision Process\n",
    "\n",
    "Reward를 구하는 공식<br>\n",
    "$ R(s, s^{\\prime}, a) $\n",
    "\n",
    "새로운 state인 $ s^{\\prime} $는 선택된 action에 의해서 영향을 받습니다.<br>\n",
    "그리고 action의 선택은 state transition function에 의해서 <br>\n",
    "$ P(s, s^{\\prime}, a) $\n",
    "\n",
    "Markov Decision Process는 4 tuple &lt;S, A, P, R&gt; 입니다.\n",
    "\n",
    "* **S** a finite set of states\n",
    "* **A** a finite set of actions\n",
    "* $ P(s, s^{\\prime}, a) = Pr(s_{t+1} = s^{\\prime} | s_t = s, a_t = a) $ <br>state s안에서 action a를 time t에 취할때, time t+1에 그 다음 state $ s^{\\prime} $를 갖게 될 확률\n",
    "* $ R(s, s^{\\prime}, a) $ 또는 $ R(s^{\\prime}, a) $ <br>이거슨.. states 그리고 action a를 했을때, state $ s^{\\prime} $으로 넘어간후 (transition) 받게될 expected reward의 값"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Algorithms\n",
    "\n",
    "MDP는 Linear Programming 또는 Dynamic Programming으로 해결할수 있습니다. 여기서는 Dynamic Programming 방식으로 해결을 합니다.\n",
    "\n",
    "$$ \\pi(s) = argmax_a\\{ \\sum_{s^{\\prime}}{ P_a(s, s^{\\prime}) R_a(s, s^{\\prime} + \\gamma V(s^{\\prime})) }  \\} $$\n",
    "\n",
    "$$ V(s) = \\sum_{s^{\\prime}}{ P_{\\pi(s)}(s, s^{\\prime})} ( R_{\\pi(s)}(s, s^{\\prime}) + \\gamma V(s^{\\prime})) $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import mdptoolbox\n",
    "from pprint import pprint as pp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "policy: (1, 0)\n",
      "(42.040598593539244, 35.58520097768905)\n"
     ]
    }
   ],
   "source": [
    "P = np.array([[[0.5, 0.5],[0.8, 0.2]],[[0, 1],[0.1, 0.9]]])\n",
    "R = np.array([[5, 10], [-1, 2]])\n",
    "vi = mdptoolbox.mdp.QLearning(P, R, 0.9)\n",
    "vi.run()\n",
    "print 'policy:', vi.policy\n",
    "print vi.V"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
