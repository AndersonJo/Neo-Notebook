{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Confusion Matrix \n",
    "\n",
    "Confusion Matrix는 일반적으로 classification model이 테스트 데이터에 대한 performance를 측정하는데 사용됩니다. (ground-truth values를 알고 있는 상태) <br>\n",
    "confusion matrix는 상대적으로 꽤 쉽게 이해할수 있기 때문에 많이 사용됩니다. 다만 용어가 매우 혼돈스럽기 때문에 주의?가 필요합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Binary Classification\n",
    "\n",
    "아래의 matrix는 165명의 환자를 대상으로 질병이 있는지 없는지 예측한 값과, 실제 값을 나타낸 것 입니다.\n",
    "\n",
    "![Confusion Matrix](images/confusion_matrix_simple2.png)\n",
    "\n",
    "\n",
    "* **True <span style=\"color:red\">Positives</span> (TP)**: 질병이 <span style=\"color:red\">있다고 예측</span>했고 실제로 질병이 있는 경우 (있는게 맞어)\n",
    "* **True <span style=\"color:red\">Negatives</span> (TN)**: 질병이 <span style=\"color:red\">없다고 예측</span>했고, 실제로 질병이 없는 경우 (없는게 맞어)\n",
    "* **False <span style=\"color:red\">Positives</span> (FP)**: 질병이 <span style=\"color:red\">있다고 예측</span>했지만, 실제로는 질병이 없음 (있는게 틀려)\n",
    "* **False <span style=\"color:red\">Negatives</span> (FN)**: 질병이 <span style=\"color:red\">없다고 예측</span>했지만, 실제로는 질병이 있음 (없는게 틀려)\n",
    "\n",
    "> Positives, Negatives는 예측한 값을 의미하고, True, False는 그 예측한 값이 맞냐 틀리냐를 말하는 상대적 개념"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Performance Measures\n",
    "\n",
    "일반적으로 classification에서 accuracy를 많이 보지만, 실무에서는 이것만 보지는 않습니다. <br>\n",
    "아래와 같은 analysis들을 보면서 해석을 합니다.\n",
    "\n",
    "자세한 내용은 [위키피디아 Confusion Matrix](https://en.wikipedia.org/wiki/Confusion_matrix)를 참고 합니다.\n",
    "\n",
    "## Accuracy \n",
    "\n",
    "* 전체 샘플중에 실제로 맞춘 비율\n",
    "* 가장 많이 사용되지만, class간의 비율이 동일할때 사용합니다.\n",
    "* 최적화에서 objective function으로 사용됩니다.\n",
    "\n",
    "$$ \\text{Accuracy} = \\frac{TP + TN}{N} = \\frac{100 + 50}{165} = 0.91  $$\n",
    "\n",
    "## Error Rate (Misclassification Rate)\n",
    "\n",
    "* 1 - accuracy \n",
    "* 얼마나 못 맞췄냐?\n",
    "\n",
    "$$ \\text{Misclassification Rate} = \\frac{FP + FN}{N} = \\frac{10 + 5}{165} = 0.09 $$\n",
    "\n",
    "\n",
    "## Recall (Sensitivity, True Positive Rate)\n",
    "\n",
    "* 실제 암에 걸린 환자들중 제대로 암이라고 판단한 비율\n",
    "* 실제 사기범들중에 유죄 판정을 내린 비율\n",
    "* 사기친 거래들중에 실제로 잡아낸 비율 -> 검거율!\n",
    "* 값이 높을수록 좋다\n",
    "\n",
    "$$ \\text{True Positive Rate} = \\frac{TP}{TP + FN} = \\frac{TP}{\\text{Actual Yes}} = \\frac{100}{100 + 5} = 0.95 $$\n",
    "\n",
    "\n",
    "## Fall-out  (False Alarm Ratio, False Positive Rate)\n",
    " \n",
    "* 실제로는 암이 아닌데 암이라고 말하는 비율\n",
    "* 실제로는 유죄가 아닌데 유죄라고 판결하는 비율\n",
    "* 실제로는 임신이 아닌데 임신이라고 오작동 하는 비율\n",
    "* 실제 정상거래들중, 사기라고 예측한 비율\n",
    "* 오판율\n",
    "* 1 - Specificity\n",
    "* 값이 높을수록 병신갖은 예측/판단을 한거다\n",
    "\n",
    "$$ \\text{True Positive Rate} = \\frac{FP}{FP + TN} = \\frac{FP}{\\text{Actual No}} =  \\frac{10}{10 + 50} = 0.17 $$\n",
    "\n",
    "\n",
    "## Specificity\n",
    "\n",
    "* 실제 아닌데, 예측도 아니라고 한 비율\n",
    "* 암이라고 판단했는데.. 실제로 맞은 비율\n",
    "* 유죄라고 판단했는데.. 실제로 맞은 비율\n",
    "* 값이 높을수록 좋다\n",
    "* 1 - False Positive Rate\n",
    "\n",
    "$$ \\text{Specificity} = \\frac{TN}{TN + FP} =  \\frac{TN}{\\text{Actual No}} = \\frac{50}{50 + 10} = 0.83 $$\n",
    "\n",
    "\n",
    "## Precision \n",
    "\n",
    "* 질병이 있다고 예측한 것중에 실제로 맞춘 비율 -> 값이 낮을 수록 암에 걸렸다고 진단했는데.. 실제로는 아닌 사람들이 있다. \n",
    "* 사기 거래에서 실제 사기를 제대로 잡아낸 비율 -> 값이 낮을 수록 무죄인 사람이 유죄로 잡혀 들어간 꼴이다.\n",
    "\n",
    "$$ \\text{Precision} = \\frac{TP}{TP + FP} = \\frac{TP}{\\text{Predicted Yes}} =  \\frac{100}{100 + 10} = 0.91 $$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  ROC (Receiver Operating Characteristics)\n",
    "\n",
    "이름이 참 이상합니다. Receiver Operating Characteristics 라니.. (직역하면.. 수신기 작동 특성?) <br>\n",
    "2차 대전때, 진주만 습격 이후로, 미군은 일본 비행기를 감지하는 레이더 시그널에 대해서 연구를 하기 시작합니다. <br>\n",
    "레이더 수신기 장비 (Radar receiver operators)의 성능을 측정하기 위해서 사용한 방법은 Receiver Operating Characteristics 입니다.<br>\n",
    "결론적으로 일본 전투기를 제대로 감지하는지 레이더의 성능을 측정하기 위한 방법으로 생겨났고.. 그래서 이름도 이렇게 됨. \n",
    "\n",
    "\n",
    "ROC curve 그래프는 세로축을 True Positive Rate (Sensitivity or Recall) 로 하고, 가로축을 False Positive Rate 으로 시각화한 그래프로서 각각의 classification thresholds마다 TPR VS FPR 을 계산한 그래프입니다. 중간의 직선은 reference line 입니다.\n",
    "\n",
    "![ROC Curve](images/roc-example1.png)\n",
    "\n",
    "\n",
    "보는 방법은 매우 간단합니다. TPR이 높고, FPR은 낮을수록 좋은거 입니다.<br>\n",
    "\n",
    "> TPR과 FPR은 서로 반비례적인 관계에 있습니다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AUC (Area Under the ROC Curve)\n",
    "\n",
    "ROC curve의 밑면적을 계산한 값입니다. \n",
    "\n",
    "![AUC](images/auc-example.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# References\n",
    "\n",
    "* http://www.dataschool.io/simple-guide-to-confusion-matrix-terminology/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
