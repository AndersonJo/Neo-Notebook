{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%pylab inline\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification Report\n",
    "\n",
    "- **class 0**: \n",
    "- **class 1**: precision = 1 \n",
    "   - TP가 있으며, FP는 없다 > 1이라고 예측해서 틀린게 없다. (1인데 틀린건 있음)\n",
    "- **class 2**: recall = 1\n",
    "   - TP가 있으며, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.25      0.50      0.33         2\n",
      "           1       1.00      0.40      0.57         5\n",
      "           2       0.50      1.00      0.67         2\n",
      "           3       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.50        10\n",
      "   macro avg       0.44      0.47      0.39        10\n",
      "weighted avg       0.65      0.50      0.49        10\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\anderson\\anaconda3\\envs\\zeta\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\anderson\\anaconda3\\envs\\zeta\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\anderson\\anaconda3\\envs\\zeta\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "y_true = [0, 0, 1, 1, 1, 1, 1, 2, 2, 3]\n",
    "y_pred = [0, 2, 1, 1, 2, 0, 0, 2, 2, 0]\n",
    "\n",
    "print(classification_report(y_true, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Confusion Matrix\n",
    "\n",
    " - Row: True Label \n",
    " - Column: Predicted Label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 0 1 0]\n",
      " [2 2 1 0]\n",
      " [0 0 2 0]\n",
      " [1 0 0 0]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5, 15.0, 'Predict')"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "\n",
    "y_true = [0, 0, 1, 1, 1, 1, 1, 2, 2, 3]\n",
    "y_pred = [0, 2, 1, 1, 2, 0, 0, 2, 2, 0]\n",
    "\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "print(cm)\n",
    "ax = sns.heatmap(cm, cmap='YlGnBu')\n",
    "ax.set_ylabel('True')\n",
    "ax.set_xlabel('Predict')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Accuracy\n",
    "\n",
    "$$ \\text{Accuracy} = \\frac{TP + TN}{N} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accuracy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n: 10\n",
      "Accuracy           : 0.5\n",
      "Normalized Accuracy: 5\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "y_true = [0, 0, 1, 1, 1, 1, 1, 2, 2, 3]\n",
    "y_pred = [0, 2, 1, 1, 2, 0, 0, 2, 2, 0]\n",
    "\n",
    "acc = accuracy_score(y_true, y_pred)\n",
    "acc_norm = accuracy_score(y_true, y_pred, normalize=False)\n",
    "\n",
    "print('n:', len(y_true))\n",
    "print(f'Accuracy           : {acc:.2}')\n",
    "print(f'Normalized Accuracy: {acc_norm}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accuracy from Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2 2 1 0]\n",
      " [1 1 2 1]\n",
      " [4 1 0 0]\n",
      " [0 1 0 1]]\n",
      "Accuracy: 0.23529411764705882\n"
     ]
    }
   ],
   "source": [
    "def cal_accuracy(cm):\n",
    "    \"\"\"\n",
    "    대각선으로 (TP + TN) 모두 합하고, 전체 N 값으로 나눈다\n",
    "    \"\"\"\n",
    "    return np.diagonal(cm).sum() / cm.sum()\n",
    "\n",
    "y_true = [0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 3, 3]\n",
    "y_pred = [1, 0, 0, 1, 2, 1, 2, 2, 3, 0, 0, 0, 0, 1, 0, 3, 1]\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "print(cm)\n",
    "\n",
    "assert accuracy_score(y_true, y_pred) == cal_accuracy(cm)\n",
    "print('Accuracy:', cal_accuracy(cm))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recall (Sensitivity, True Positive Rate)\n",
    "\n",
    "$$ \\text{True Positive Rate} = \\frac{TP}{TP + FN} $$\n",
    "\n",
    " - 단점: 전부다 1로 예측하면, TP는 다 맞추고, FN은 0이 되면서, recall의 예측값은 1이 된다"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "**average parameter**\n",
    "  - **None**  : 각각의 클래스마다의 recall값을 계산한다\n",
    "  - **binary**: (default) binary classification에서 사용 \n",
    "  - **micro** : 전체 클래스 데이터 관점에서의 total true positives, false negatives, false positives 를 계산\n",
    "  - **macro** : 각각의 label마다의 recall의 unweighted mean을 계산한다. 따라서 label imbalance를 고려하지 않는다"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recall "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recalls          : [0.5 0.4 1.  0. ]\n",
      "Recall (micro)   : 0.5\n",
      "Recall (macro)   : 0.47\n",
      "Recall (weighted): 0.5\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import recall_score\n",
    "\n",
    "y_true = [0, 0, 1, 1, 1, 1, 1, 2, 2, 3]\n",
    "y_pred = [0, 2, 1, 1, 2, 0, 0, 2, 2, 0]\n",
    "\n",
    "\n",
    "recalls = recall_score(y_true, y_pred, average=None)\n",
    "recall_micro = recall_score(y_true, y_pred, average='micro')\n",
    "recall_macro = recall_score(y_true, y_pred, average='macro')\n",
    "recall_weighted = recall_score(y_true, y_pred, average='weighted')\n",
    "\n",
    "print('Recalls          :', recalls)\n",
    "print(f'Recall (micro)   : {recall_micro:.2}')\n",
    "print(f'Recall (macro)   : {recall_macro:.2}')\n",
    "print(f'Recall (weighted): {recall_weighted:.2}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recall from Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 0 1 0]\n",
      " [2 2 1 0]\n",
      " [0 0 2 0]\n",
      " [1 0 0 0]]\n",
      "recalls        : [0.5 0.4 1.  0. ]\n",
      "recalls (macro): 0.475\n",
      "recalls (micro): 0.5\n"
     ]
    }
   ],
   "source": [
    "def cal_recall(cm, average=None):\n",
    "    data = [np.nan_to_num(cm[i, i] / cm[i, :].sum()) for i in range(cm.shape[0])]\n",
    "    data = np.array(data)\n",
    "    \n",
    "    if average is None:\n",
    "        return data\n",
    "    elif average == 'macro':\n",
    "        return data.mean()\n",
    "    elif average == 'micro':\n",
    "        weight = cm.sum(axis=1)\n",
    "        return (data * weight).sum() / weight.sum()\n",
    "    return data\n",
    "\n",
    "# y_true = [0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 3, 3]\n",
    "# y_pred = [1, 0, 0, 1, 2, 1, 2, 2, 3, 0, 0, 0, 0, 1, 0, 3, 1]\n",
    "\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "print(cm)\n",
    "answer = recall_score(y_true, y_pred, average=None)\n",
    "assert (answer == cal_recall(cm, average=None)).all()\n",
    "\n",
    "answer = recall_score(y_true, y_pred, average='macro')\n",
    "assert answer == cal_recall(cm, average='macro')\n",
    "\n",
    "answer = recall_score(y_true, y_pred, average='micro')\n",
    "assert answer == cal_recall(cm, average='micro')\n",
    "\n",
    "\n",
    "print('recalls        :', cal_recall(cm, average=None))\n",
    "print('recalls (macro):', cal_recall(cm, average='macro'))\n",
    "print('recalls (micro):', cal_recall(cm, average='micro'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Precision\n",
    "\n",
    "$$ \\text{Precision} = \\frac{TP}{TP + FP} = \\frac{TP}{\\text{Predicted Yes}} $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precisions       : [0.25 1.   0.5  0.  ]\n",
      "Precision (micro)   : 0.5\n",
      "Precision (macro)   : 0.44\n",
      "Precision (weighted): 0.65\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score\n",
    "\n",
    "y_true = [0, 0, 1, 1, 1, 1, 1, 2, 2, 3]\n",
    "y_pred = [0, 2, 1, 1, 2, 0, 0, 2, 2, 0]\n",
    "\n",
    "precisions = precision_score(y_true, y_pred, average=None, zero_division=False)\n",
    "precision_micro = precision_score(y_true, y_pred, average='micro', zero_division=False)\n",
    "precision_macro = precision_score(y_true, y_pred, average='macro', zero_division=False)\n",
    "precision_weighted = precision_score(y_true, y_pred, average='weighted', zero_division=False)\n",
    "\n",
    "print('Precisions       :', precisions)\n",
    "print(f'Precision (micro)   : {precision_micro:.2}')\n",
    "print(f'Precision (macro)   : {precision_macro:.2}')\n",
    "print(f'Precision (weighted): {precision_weighted:.2}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Precision from Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precisions        : [0.25 1.   0.5  0.  ]\n",
      "Precision (macro) : 0.44\n",
      "Precision (micro) : 0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-235-10a483400abf>:2: RuntimeWarning: invalid value encountered in longlong_scalars\n",
      "  data = [np.nan_to_num(cm[i, i] / cm[:, i].sum()) for i in range(cm.shape[0])]\n",
      "<ipython-input-235-10a483400abf>:2: RuntimeWarning: invalid value encountered in longlong_scalars\n",
      "  data = [np.nan_to_num(cm[i, i] / cm[:, i].sum()) for i in range(cm.shape[0])]\n",
      "<ipython-input-235-10a483400abf>:2: RuntimeWarning: invalid value encountered in longlong_scalars\n",
      "  data = [np.nan_to_num(cm[i, i] / cm[:, i].sum()) for i in range(cm.shape[0])]\n"
     ]
    }
   ],
   "source": [
    "def cal_precision(cm, average=None):\n",
    "    data = [np.nan_to_num(cm[i, i] / cm[:, i].sum()) for i in range(cm.shape[0])]\n",
    "    data = np.array(data)\n",
    "\n",
    "    if average is None:\n",
    "        return data\n",
    "    elif average == 'macro':\n",
    "        return data.mean()\n",
    "    elif average == 'micro':\n",
    "        weight = cm.sum(axis=0)\n",
    "        return (data * weight).sum() / weight.sum()\n",
    "    return data\n",
    "\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "answer = precision_score(y_true, y_pred, average=None, zero_division=False)\n",
    "assert (answer == cal_precision(cm)).all()\n",
    "\n",
    "answer = precision_score(y_true, y_pred, average='macro', zero_division=False)\n",
    "assert answer == cal_precision(cm, average='macro')\n",
    "\n",
    "answer = precision_score(y_true, y_pred, average='micro', zero_division=False)\n",
    "assert answer == cal_precision(cm, average='micro')\n",
    "\n",
    "\n",
    "print(f'Precisions        : {cal_precision(cm)}')\n",
    "print(f'Precision (macro) : {cal_precision(cm, average=\"macro\"):.2}')\n",
    "print(f'Precision (micro) : {cal_precision(cm, average=\"micro\"):.2}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# F1 Score\n",
    "\n",
    "$$ \\text{F1 Score} = 2 \\cdot\n",
    "\\frac{\\text{precision} \\times \\text{recall}}{\\text{precision} + \\text{recall}} $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1       : [0.33333333 0.57142857 0.66666667 0.        ]\n",
      "F1 (micro)   : 0.5\n",
      "F1 (macro)   : 0.39\n",
      "F1 (weighted): 0.49\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "\n",
    "y_true = [0, 0, 1, 1, 1, 1, 1, 2, 2, 3]\n",
    "y_pred = [0, 2, 1, 1, 2, 0, 0, 2, 2, 0]\n",
    "\n",
    "f1_score(y_true, y_pred, average=None)\n",
    "\n",
    "f1 = f1_score(y_true, y_pred, average=None)\n",
    "f1_micro = f1_score(y_true, y_pred, average='micro')\n",
    "f1_macro = f1_score(y_true, y_pred, average='macro')\n",
    "f1_weighted = f1_score(y_true, y_pred, average='weighted')\n",
    "\n",
    "print('F1       :', f1)\n",
    "print(f'F1 (micro)   : {f1_micro:.2}')\n",
    "print(f'F1 (macro)   : {f1_macro:.2}')\n",
    "print(f'F1 (weighted): {f1_weighted:.2}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
