{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction Auto-Encoder \n",
    "\n",
    "### Autoencoders\n",
    "\n",
    "2000이후 가장 중요한 결과물중에 하나는 Deep Belief Networks입니다. Deep Belief Network는 초기는 random initialization이 아닌 각각의 Layers들을 unsupervised learning algorithm으로 미리학습(pretraining)시키는게 더 좋은 결과를 내 놓는다는 아이디어에 근거를 둡니다. Deep Belief Networks는 Restricted Boltzmann Machines, 그리고 Deep Autoencoders에 기반을 두고 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Compression via Autoencoders\n",
    "\n",
    "예를 들어서 모바일 데이터를 클라우드로 보내려고 합니다.<br>\n",
    "이때 데이터는 다음과 같은 좌표로 구성이 되어 있으며, 눈으로 보면 알수 있듯이 x에 비해서 y값이 2배이상 빠르게 증가하는것을 알 수 있습니다.\n",
    "\n",
    "<img src=\"images/autoencoder01.png\" class=\"img-responsive img-rounded\">\n",
    "\n",
    "즉 이러한 관계를 이용하여, 데이터의 1 dimension만 클라우드로 보낸다면 데이터의 양을 compress할 수 있을 것입니다. <br>\n",
    "클라우드에서는 받은 데이터를 2배정도 증가시켜서 대략의 데이터값을 복원할 수 있습니다. \n",
    "\n",
    "1. **Encoding**: $ x^{(i)} $ data의 compress 해서 $ z^{(i)} $ data로 변환시킵니다.\n",
    "2. **Sending**: $ z^{(i)} $를 클라우드로 보냅니다.\n",
    "3. **Decoding**: $ z^{(i)}$ 데이터를  $ \\hat{x}^{(i)} $ 로 변환시킵니다.\n",
    "\n",
    "### $$ z^{(i)} = W_1  x^{(i)} + b_1$$\n",
    "\n",
    "### $$ \\hat{x}^{(i)} = W_2 z^{(i)} + b_2 $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cost function\n",
    "\n",
    "Gradient descent를 활용하기 위해서 sum of sqaured error (SSE)를 사용합니다.\n",
    "\n",
    "### $$ \\sum^m_{i=1} \\left( \\hat{x}^{(i)} - x^{(i)} \\right)  $$\n",
    "\n",
    "###  $$ = \\sum^m_{i=1} \\left( W_2 z^{(i)} + b_2 - x^{(i)} \\right)  $$\n",
    "\n",
    "###  $$ = \\sum^m_{i=1} \\left( W_2 (W_1  x^{(i)} + b_1) + b_2 - x^{(i)} \\right)  $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Autoencoders as an initialization method\n",
    "\n",
    "Autoencoders는 data compression, visualization등등에서 활용될수 있습니다. 2006~2007년 사이에 Autoencoders가 neural network를 pretrain하는데 사용될수 있음을 알게됩니다. \n",
    "\n",
    "\n",
    "**Pretraining Steps**\n",
    "\n",
    "1. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### References\n",
    "\n",
    "* [haha](http://ai.stanford.edu/~quocle/tutorial2.pdf)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
