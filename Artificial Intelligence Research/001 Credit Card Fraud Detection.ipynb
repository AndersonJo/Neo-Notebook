{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Credit Card Fraud Detection "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/usr/local/lib/python3.6/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "%pylab inline\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Embedding, LSTM\n",
    "\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.utils import resample\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Dropout\n",
    "from keras.optimizers import SGD, RMSprop\n",
    "from keras.regularizers import l2\n",
    "from keras.backend.tensorflow_backend import set_session\n",
    "from keras.utils import np_utils\n",
    "import keras\n",
    "\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "from IPython.display import SVG, Image\n",
    "from keras.utils.visualize_util import model_to_dot\n",
    "\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data\n",
    "\n",
    "[Credit Card Fraud Detection - Kaggle](https://www.kaggle.com/dalpozz/creditcardfraud)에서 다운받을수 있습니다.\n",
    "\n",
    "데이터는 2013년 유럽 카드회사의 이틀동안 일어난 transactions에 관한 것이며, <br>\n",
    "492건의 frauds 가 284,807건의 transactions중에 일어 났습니다.\n",
    "\n",
    "Class에서 1은 fraud를 뜻하며, 0은 아닌것을 말합니다.\n",
    "\n",
    "Time데이터는 첫번재 Column으로부터 몇초 이후에 발생한 transaction이라는 뜻입니다. <br>\n",
    "나머지 데이터들은 PCA의 규제에 의해서 어떤 데이터인지 밝히지 않습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/sklearn/preprocessing/data.py:586: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "/usr/local/lib/python3.6/site-packages/sklearn/preprocessing/data.py:649: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('/dataset/time-series/credit-card-fraud-detection/creditcard.csv')\n",
    "\n",
    "# Preprocessing Amount\n",
    "amt_scale = StandardScaler()\n",
    "data['NormAmount'] =  amt_scale.fit_transform(data['Amount'])\n",
    "\n",
    "# Split Train and Test Data\n",
    "X = data.drop(['Time', 'Amount', 'Class'], axis=1).as_matrix()\n",
    "Y = data['Class'].as_matrix()\n",
    "\n",
    "# Standardization\n",
    "scale_x = StandardScaler()\n",
    "X = scale_x.fit_transform(X)\n",
    "\n",
    "train_x, test_x, train_y, test_y = train_test_split(X, Y, test_size=0.25, random_state=1)\n",
    "\n",
    "fraud_test_y = test_y == 1\n",
    "fraud_test_x = test_x[fraud_test_y]\n",
    "fraud_test_y = test_y[fraud_test_y]\n",
    "\n",
    "train_category_y = np_utils.to_categorical(train_y)\n",
    "test_category_y = np_utils.to_categorical(test_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Checking the number of fraud transactions in training and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of Fraud transactions in Training Data: 381\n",
      "The number of Fraud transactions in Test Data: 111\n"
     ]
    }
   ],
   "source": [
    "print('The number of Fraud transactions in Training Data:', train_y[train_y == 1].shape[0])\n",
    "print('The number of Fraud transactions in Test Data:',  test_y[test_y == 1].shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Checking the target classes\n",
    "\n",
    "fraud transactions이 492개밖에 되지 않기 때문에, 일반적인 classification algorithm으로 돌리면 물론 정확도는 매우 높게 나오지만.. \n",
    "실상은 1에 해당하는 fraud transactions에서는 대부분 틀릴 가능성이 매우 높습니다. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    284315\n",
       "1       492\n",
       "Name: Class, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.value_counts(data['Class'], sort=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resampling\n",
    "\n",
    "resampling에는 여러가지 방법이 있습니다. \n",
    "\n",
    "1. Over Sampling: SMOTE (Synthetic Minority Over-Sampling Technique)\n",
    "2. Under Sampling\n",
    "\n",
    "아래의 resample function에서는 5:5의 비율로 under sampling을 해줍니다.<br>\n",
    "resample을 하면서 시간관계가 어차피 깨지기 때문에 (사실 각각의 transactions들 사이에 상관관계가 있는지도 모르겠음)<br>\n",
    "shuffle을 통해서 train되는 데이터를 augment해줍니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def resample(X, Y):\n",
    "    index = np.arange(Y.shape[0])\n",
    "    fraud_indices = index[Y == 1]\n",
    "    normal_indices = index[Y == 0]\n",
    "    random_normal_indices = np.random.choice(normal_indices, len(fraud_indices))\n",
    "    \n",
    "    sample_indices = np.concatenate([fraud_indices, random_normal_indices])\n",
    "    np.random.shuffle(sample_indices)\n",
    "    sample_indices = np.array(sample_indices)\n",
    "    \n",
    "    sample_x = X[sample_indices]\n",
    "    sample_y = Y[sample_indices]\n",
    "    return sample_x, sample_y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression\n",
    "\n",
    "전체적으로 0.99% accuracy를 보이지만, 실제 fraud data만 test를 했을때는 0.57%로.. 실질적으로 못맞추는 수준입니다.<br>\n",
    "사실 일반적인 알고리즘으로 학습시키기 위해서는 over sampling (SMOTE 같은) 또는 under sampling이 필요합니다.<br>\n",
    "sampling을 통해서 skewed data를 보정하는 것입니다.\n",
    "\n",
    "#### resample 없이 데이터 학습뒤 예측하면.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.99914328249206485"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lg = LogisticRegression()\n",
    "lg.fit(train_x, train_y)\n",
    "predicted_y = lg.predict(test_x)\n",
    "accuracy_score(test_y, predicted_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.57657657657657657"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_y = lg.predict(fraud_test_x)\n",
    "accuracy_score(fraud_test_y, predicted_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### resampled data로 학습뒤 예측하면...\n",
    "0.88 ~ 0.92 까지 예측률이 높아지게 됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.96657397264121792"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lg = LogisticRegression()\n",
    "lg.fit(*resample(train_x, train_y))\n",
    "\n",
    "predicted_y = lg.predict(test_x)\n",
    "accuracy_score(test_y, predicted_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.89189189189189189"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_y = lg.predict(fraud_test_x)\n",
    "accuracy_score(fraud_test_y, predicted_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Tree\n",
    "\n",
    "#### resample 없이 데이터 학습뒤 예측하면.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.99932586163310022"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dtc = DecisionTreeClassifier(max_depth=10, criterion='entropy')\n",
    "dtc.fit(train_x, train_y)\n",
    "predicted_y = dtc.predict(test_x)\n",
    "accuracy_score(test_y, predicted_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.76576576576576572"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_y = dtc.predict(fraud_test_x)\n",
    "accuracy_score(fraud_test_y, predicted_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### resampled data로 학습뒤 예측하면..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.905606584085\n",
      "0.896435493385\n",
      "0.915957416926\n"
     ]
    }
   ],
   "source": [
    "dtc = DecisionTreeClassifier(max_depth=10, criterion='entropy')\n",
    "for i in range(3):\n",
    "    dtc.fit(*resample(train_x, train_y))\n",
    "    predicted_y = dtc.predict(test_x)\n",
    "    print(accuracy_score(test_y, predicted_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.86486486486486491"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_y = dtc.predict(fraud_test_x)\n",
    "accuracy_score(fraud_test_y, predicted_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Learning with Keras\n",
    "\n",
    "하.. 드디어 딥러닝으로.. 해보면 어떤 결과가 나올 것인가.. Sampling VS UnSampling!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       ..., \n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.],\n",
       "       [ 0.,  1.]])"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_y = np_utils.to_categorical(train_y)\n",
    "train_y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "config = tf.ConfigProto()\n",
    "config.gpu_options.per_process_gpu_memory_fraction = 0.1\n",
    "set_session(tf.Session(config=config))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "dense01 (Dense)                  (None, 1)             30          dense_input_2[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "activation01 (Activation)        (None, 1)             0           dense01[0][0]                    \n",
      "====================================================================================================\n",
      "Total params: 30\n",
      "Trainable params: 30\n",
      "Non-trainable params: 0\n",
      "____________________________________________________________________________________________________\n"
     ]
    },
    {
     "data": {
      "image/svg+xml": [
       "<svg height=\"221pt\" viewBox=\"0.00 0.00 302.00 221.00\" width=\"302pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g class=\"graph\" id=\"graph0\" transform=\"scale(1 1) rotate(0) translate(4 217)\">\n",
       "<title>G</title>\n",
       "<polygon fill=\"white\" points=\"-4,4 -4,-217 298,-217 298,4 -4,4\" stroke=\"none\"/>\n",
       "<!-- 139748789054600 -->\n",
       "<g class=\"node\" id=\"node1\"><title>139748789054600</title>\n",
       "<polygon fill=\"none\" points=\"0,-166.5 0,-212.5 294,-212.5 294,-166.5 0,-166.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"81.5\" y=\"-185.8\">dense_input_2: InputLayer</text>\n",
       "<polyline fill=\"none\" points=\"163,-166.5 163,-212.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"190.5\" y=\"-197.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"163,-189.5 218,-189.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"190.5\" y=\"-174.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"218,-166.5 218,-212.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"256\" y=\"-197.3\">(None, 29)</text>\n",
       "<polyline fill=\"none\" points=\"218,-189.5 294,-189.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"256\" y=\"-174.3\">(None, 29)</text>\n",
       "</g>\n",
       "<!-- 139748789054544 -->\n",
       "<g class=\"node\" id=\"node2\"><title>139748789054544</title>\n",
       "<polygon fill=\"none\" points=\"30.5,-83.5 30.5,-129.5 263.5,-129.5 263.5,-83.5 30.5,-83.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"81.5\" y=\"-102.8\">dense01: Dense</text>\n",
       "<polyline fill=\"none\" points=\"132.5,-83.5 132.5,-129.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"160\" y=\"-114.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"132.5,-106.5 187.5,-106.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"160\" y=\"-91.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"187.5,-83.5 187.5,-129.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"225.5\" y=\"-114.3\">(None, 29)</text>\n",
       "<polyline fill=\"none\" points=\"187.5,-106.5 263.5,-106.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"225.5\" y=\"-91.3\">(None, 1)</text>\n",
       "</g>\n",
       "<!-- 139748789054600&#45;&gt;139748789054544 -->\n",
       "<g class=\"edge\" id=\"edge1\"><title>139748789054600-&gt;139748789054544</title>\n",
       "<path d=\"M147,-166.366C147,-158.152 147,-148.658 147,-139.725\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"150.5,-139.607 147,-129.607 143.5,-139.607 150.5,-139.607\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 139748788941152 -->\n",
       "<g class=\"node\" id=\"node3\"><title>139748788941152</title>\n",
       "<polygon fill=\"none\" points=\"11,-0.5 11,-46.5 283,-46.5 283,-0.5 11,-0.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"85\" y=\"-19.8\">activation01: Activation</text>\n",
       "<polyline fill=\"none\" points=\"159,-0.5 159,-46.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"186.5\" y=\"-31.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"159,-23.5 214,-23.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"186.5\" y=\"-8.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"214,-0.5 214,-46.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"248.5\" y=\"-31.3\">(None, 1)</text>\n",
       "<polyline fill=\"none\" points=\"214,-23.5 283,-23.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"248.5\" y=\"-8.3\">(None, 1)</text>\n",
       "</g>\n",
       "<!-- 139748789054544&#45;&gt;139748788941152 -->\n",
       "<g class=\"edge\" id=\"edge2\"><title>139748789054544-&gt;139748788941152</title>\n",
       "<path d=\"M147,-83.3664C147,-75.1516 147,-65.6579 147,-56.7252\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"150.5,-56.6068 147,-46.6068 143.5,-56.6069 150.5,-56.6068\" stroke=\"black\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>"
      ],
      "text/plain": [
       "<IPython.core.display.SVG object>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def generate_model():\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Dense(output_dim=1, input_dim=29, name='dense01'))\n",
    "    model.add(Activation('sigmoid', name='activation01'))\n",
    "#     model.add(Dropout(0.5))\n",
    "#     model.add(Dense(output_dim=256, input_dim=512, name='dense02'))\n",
    "#     model.add(Activation('relu', name='activation02'))\n",
    "#     model.add(Dropout(0.5))\n",
    "#     model.add(Dense(output_dim=1, name='dense03'))\n",
    "#     model.add(Activation('softmax', name='activation03'))\n",
    "\n",
    "    model.compile(loss='binary_crossentropy', \n",
    "                  optimizer='adam', \n",
    "                  metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "\n",
    "# # Visualization\n",
    "model = generate_model()\n",
    "model.summary()\n",
    "SVG(model_to_dot(model, show_shapes=True).create(prog='dot', format='svg'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### resample 없이 데이터 학습뒤 예측하면.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "14s - loss: 15.9139 - acc: 0.0018\n",
      "Epoch 2/10\n",
      "13s - loss: 15.9139 - acc: 0.0018\n",
      "Epoch 3/10\n",
      "13s - loss: 15.9139 - acc: 0.0018\n",
      "Epoch 4/10\n",
      "14s - loss: 15.9139 - acc: 0.0018\n",
      "Epoch 5/10\n",
      "13s - loss: 15.9139 - acc: 0.0018\n",
      "Epoch 6/10\n",
      "13s - loss: 15.9139 - acc: 0.0018\n",
      "Epoch 7/10\n",
      "12s - loss: 15.9139 - acc: 0.0018\n",
      "Epoch 8/10\n",
      "12s - loss: 15.9139 - acc: 0.0018\n",
      "Epoch 9/10\n",
      "13s - loss: 15.9139 - acc: 0.0018\n",
      "Epoch 10/10\n",
      "14s - loss: 15.9139 - acc: 0.0018\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f7984241160>"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = generate_model()\n",
    "model.fit(train_x, train_y, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.00155894497346\n"
     ]
    }
   ],
   "source": [
    "predicted_y = model.predict(test_x)\n",
    "predicted_y = predicted_y.reshape(predicted_y.shape[0])\n",
    "print(accuracy_score(test_y, predicted_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_y = model.predict(fraud_test_x)\n",
    "predicted_y = predicted_y.reshape(predicted_y.shape[0])\n",
    "accuracy_score(fraud_test_y, predicted_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### resampled data로 학습뒤 예측하면..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "0s - loss: 0.6870 - acc: 0.6404\n",
      "Epoch 2/10\n",
      "0s - loss: 0.6135 - acc: 0.6745\n",
      "Epoch 3/10\n",
      "0s - loss: 0.5767 - acc: 0.6903\n",
      "Epoch 4/10\n",
      "0s - loss: 0.5510 - acc: 0.7021\n",
      "Epoch 5/10\n",
      "0s - loss: 0.5304 - acc: 0.7100\n",
      "Epoch 6/10\n",
      "0s - loss: 0.5105 - acc: 0.7165\n",
      "Epoch 7/10\n",
      "0s - loss: 0.4935 - acc: 0.7231\n",
      "Epoch 8/10\n",
      "0s - loss: 0.4777 - acc: 0.7388\n",
      "Epoch 9/10\n",
      "0s - loss: 0.4633 - acc: 0.7415\n",
      "Epoch 10/10\n",
      "0s - loss: 0.4490 - acc: 0.7441\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f1985469c18>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = generate_model()\n",
    "model.fit(*resample(train_x, train_y), verbose=2, nb_epoch=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.15493922  0.48184815  0.37785113 ...,  0.50462222  0.24449366\n",
      "  0.71220315]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "estimator should be an estimator implementing 'fit' method, array([0, 0, 0, ..., 0, 0, 0]) was passed",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-e9511de63616>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mpredicted_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredicted_y\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredicted_y\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredicted_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcross_val_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredicted_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36mcross_val_score\u001b[0;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch)\u001b[0m\n\u001b[1;32m    130\u001b[0m     \u001b[0mcv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_cv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclassifier\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mis_classifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    131\u001b[0m     \u001b[0mcv_iter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroups\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 132\u001b[0;31m     \u001b[0mscorer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_scoring\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mscoring\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    133\u001b[0m     \u001b[0;31m# We clone the estimator to make sure that all the folds are\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m     \u001b[0;31m# independent, and that it is pickle-able.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/sklearn/metrics/scorer.py\u001b[0m in \u001b[0;36mcheck_scoring\u001b[0;34m(estimator, scoring, allow_none)\u001b[0m\n\u001b[1;32m    248\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'fit'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    249\u001b[0m         raise TypeError(\"estimator should be an estimator implementing \"\n\u001b[0;32m--> 250\u001b[0;31m                         \"'fit' method, %r was passed\" % estimator)\n\u001b[0m\u001b[1;32m    251\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscoring\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstring_types\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    252\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mget_scorer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscoring\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: estimator should be an estimator implementing 'fit' method, array([0, 0, 0, ..., 0, 0, 0]) was passed"
     ]
    }
   ],
   "source": [
    "predicted_y = model.predict(test_x)\n",
    "predicted_y = predicted_y.reshape(predicted_y.shape[0])\n",
    "print(predicted_y)\n",
    "print(cross_val_score(test_y, predicted_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_y = model.predict(fraud_test_x)\n",
    "predicted_y = predicted_y.reshape(predicted_y.shape[0])\n",
    "accuracy_score(fraud_test_y, predicted_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "dense_94 (Dense)                 (None, 1)             30          dense_input_40[0][0]             \n",
      "====================================================================================================\n",
      "Total params: 30\n",
      "Trainable params: 30\n",
      "Non-trainable params: 0\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "w = model.weights[0]\n",
    "model.summary()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
