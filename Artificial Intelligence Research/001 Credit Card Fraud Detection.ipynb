{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Credit Card Fraud Detection "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/usr/local/lib/python3.6/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "%pylab inline\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Embedding, LSTM\n",
    "\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.utils import resample\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data\n",
    "\n",
    "[Credit Card Fraud Detection - Kaggle](https://www.kaggle.com/dalpozz/creditcardfraud)에서 다운받을수 있습니다.\n",
    "\n",
    "데이터는 2013년 유럽 카드회사의 이틀동안 일어난 transactions에 관한 것이며, <br>\n",
    "492건의 frauds 가 284,807건의 transactions중에 일어 났습니다.\n",
    "\n",
    "Class에서 1은 fraud를 뜻하며, 0은 아닌것을 말합니다.\n",
    "\n",
    "Time데이터는 첫번재 Column으로부터 몇초 이후에 발생한 transaction이라는 뜻입니다. <br>\n",
    "나머지 데이터들은 PCA의 규제에 의해서 어떤 데이터인지 밝히지 않습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/sklearn/preprocessing/data.py:586: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "/usr/local/lib/python3.6/site-packages/sklearn/preprocessing/data.py:649: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('/dataset/time-series/credit-card-fraud-detection/creditcard.csv')\n",
    "\n",
    "# Preprocessing Amount\n",
    "amt_scale = StandardScaler()\n",
    "data['NormAmount'] =  amt_scale.fit_transform(data['Amount'])\n",
    "\n",
    "# Split Train and Test Data\n",
    "X = data.drop(['Time', 'Amount', 'Class'], axis=1).as_matrix()\n",
    "Y = data['Class'].as_matrix()\n",
    "\n",
    "train_x, test_x, train_y, test_y = train_test_split(X, Y, test_size=0.25, random_state=1)\n",
    "\n",
    "fraud_test_y = test_y == 1\n",
    "fraud_test_x = test_x[fraud_test_y]\n",
    "fraud_test_y = test_y[fraud_test_y]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Checking the number of fraud transactions in training and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of Fraud transactions in Training Data: 381\n",
      "The number of Fraud transactions in Test Data: 111\n"
     ]
    }
   ],
   "source": [
    "print('The number of Fraud transactions in Training Data:', train_y[train_y == 1].shape[0])\n",
    "print('The number of Fraud transactions in Test Data:',  test_y[test_y == 1].shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Checking the target classes\n",
    "\n",
    "fraud transactions이 492개밖에 되지 않기 때문에, 일반적인 classification algorithm으로 돌리면 물론 정확도는 매우 높게 나오지만.. \n",
    "실상은 1에 해당하는 fraud transactions에서는 대부분 틀릴 가능성이 매우 높습니다. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    284315\n",
       "1       492\n",
       "Name: Class, dtype: int64"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.value_counts(data['Class'], sort=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resampling\n",
    "\n",
    "resampling에는 여러가지 방법이 있습니다. \n",
    "\n",
    "1. Over Sampling: SMOTE (Synthetic Minority Over-Sampling Technique)\n",
    "2. Under Sampling\n",
    "\n",
    "아래의 resample function에서는 5:5의 비율로 under sampling을 해줍니다.<br>\n",
    "resample을 하면서 시간관계가 어차피 깨지기 때문에 (사실 각각의 transactions들 사이에 상관관계가 있는지도 모르겠음)<br>\n",
    "shuffle을 통해서 train되는 데이터를 augment해줍니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def resample(X, Y):\n",
    "    index = np.arange(Y.shape[0])\n",
    "    fraud_indices = index[Y == 1]\n",
    "    normal_indices = index[Y == 0]\n",
    "    random_normal_indices = np.random.choice(normal_indices, len(fraud_indices))\n",
    "    \n",
    "    sample_indices = np.concatenate([fraud_indices, random_normal_indices])\n",
    "    np.random.shuffle(sample_indices)\n",
    "    sample_indices = np.array(sample_indices)\n",
    "    \n",
    "    sample_x = X[sample_indices]\n",
    "    sample_y = Y[sample_indices]\n",
    "    return sample_x, sample_y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression\n",
    "\n",
    "전체적으로 0.99% accuracy를 보이지만, 실제 fraud data만 test를 했을때는 0.57%로.. 실질적으로 못맞추는 수준입니다.<br>\n",
    "사실 일반적인 알고리즘으로 학습시키기 위해서는 over sampling (SMOTE 같은) 또는 under sampling이 필요합니다.<br>\n",
    "sampling을 통해서 skewed data를 보정하는 것입니다.\n",
    "\n",
    "#### resample 없이 데이터 학습뒤 예측하면.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.99914328249206485"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lg = LogisticRegression()\n",
    "lg.fit(train_x, train_y)\n",
    "predicted_y = lg.predict(test_x)\n",
    "accuracy_score(test_y, predicted_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.57657657657657657"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_y = lg.predict(fraud_test_x)\n",
    "accuracy_score(fraud_test_y, predicted_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### resampled data로 학습뒤 예측하면...\n",
    "0.88 ~ 0.92 까지 예측률이 높아지게 됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.96132131119912367"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lg = LogisticRegression()\n",
    "lg.fit(*resample(train_x, train_y))\n",
    "\n",
    "predicted_y = lg.predict(test_x)\n",
    "accuracy_score(test_y, predicted_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.91891891891891897"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_y = lg.predict(fraud_test_x)\n",
    "accuracy_score(fraud_test_y, predicted_y)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
